{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TALL模型实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime  # 用于计算时间\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#import tensorflow.contrib.keras as kr\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from torchtext import data\n",
    "import jieba\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=15)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/wuxun/Desktop/Data/TALL/traning/training.txt'\n",
    "val_path = 'C:/Users/wuxun/Desktop/Data/TALL/validation/validation.txt'\n",
    "vocab_dir = 'C:/Users/wuxun/Desktop/Data/vocab.txt'\n",
    "csv_path = 'D:/csv/'\n",
    "save_path = 'C:/Users/wuxun/Desktop/Data/TALL/save_model/'\n",
    "test_path = 'C:/Users/wuxun/Desktop/Data/TALL/testing/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(vocab_dir):\n",
    "\n",
    "    \"\"\"读取词汇表\"\"\"\n",
    "\n",
    "    with open(vocab_dir) as fp:\n",
    "        words = [(_.strip()) for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(path, csv_path):\n",
    "    '''\n",
    "    获得最终的数据集\n",
    "    path:文本数据集\n",
    "    csv_path\n",
    "    '''\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    target_csv=[]\n",
    "    target_time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end)//2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time/time_length*500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            #上下文信息\n",
    "            target_frame_start = int(cur_start/time_length*500)\n",
    "            target_frame_end = int(cur_end/time_length*500)\n",
    "            if target_frame_start == target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num - 3, 0)\n",
    "            if  target_frame_end ==target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num + 3, 499)\n",
    "                \n",
    "            pre_context = np.zeros([target_frame_num - target_frame_start, 512], dtype=np.float32)\n",
    "            post_context = np.zeros([target_frame_end - target_frame_num, 512], dtype=np.float32) \n",
    "            for i in range(target_frame_num - target_frame_start):\n",
    "                pre_context[i] = frame_sum.loc[i]\n",
    "                \n",
    "            for i in range(target_frame_end - target_frame_num):\n",
    "                post_context[i] = frame_sum.loc[i]\n",
    "            \n",
    "            #对pre_context和post_context取均值\n",
    "            pre_context = np.mean(pre_context, axis=0)\n",
    "            post_context = np.mean(post_context, axis=0)\n",
    "            \n",
    "            #对三段信息进行拼接\n",
    "            image = np.hstack((pre_context, target_middle_frame, post_context))\n",
    "            \n",
    "            target_csv.append(image)\n",
    "            target_time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(target_csv),len(target_time_list))\n",
    "    \n",
    "    return batch_seq, target_csv, target_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.0  107.0 219.22\n",
      "出现重复！\n",
      "50.0  51.0 244.37\n",
      "出现重复！\n",
      "87.0  88.0 244.37\n",
      "出现重复！\n",
      "30.0  31.0 129.24\n",
      "出现重复！\n",
      "258.0  259.0 396.3\n",
      "出现重复！\n",
      "31.0  32.0 88.22\n",
      "出现重复！\n",
      "51.0  52.0 271.07\n",
      "出现重复！\n",
      "1548 1548 1548\n"
     ]
    }
   ],
   "source": [
    "sentence_tarin_batch, target_train_csv, target_train_list = get_dict(train_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.0  148.0 561.49\n",
      "出现重复！\n",
      "262.0  263.0 352.4\n",
      "出现重复！\n",
      "183.0  184.0 329.89\n",
      "出现重复！\n",
      "281.0  282.0 349.68\n",
      "出现重复！\n",
      "523 523 523\n"
     ]
    }
   ],
   "source": [
    "sentence_val_batch, target_val_csv, target_val_list = get_dict(val_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(x_batch, target_csv, target_list, batch_size = 64):\n",
    "    \"\"\"\n",
    "    生成批次数据\n",
    "    \"\"\"\n",
    "    data_len = x_batch.shape[0]\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    \n",
    "    x_batch_shuffle = x_batch[indices]\n",
    "    y_csv_shuffle = np.array(target_csv)[indices]\n",
    "    target_list = np.array(target_list)[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_batch_shuffle[start_id:end_id], y_csv_shuffle[start_id:end_id], target_list[start_id:end_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TALL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TALL, self).__init__()\n",
    "        self.semantic_size = 128 # the size of visual and semantic comparison size\n",
    "        #self.sentence_embedding_size = 4800\n",
    "        self.visual_feature_dim = 1536\n",
    "        self.v2s_lt = nn.Linear(self.visual_feature_dim, self.semantic_size)#视觉提取\n",
    "        self.s2s_lt = nn.Linear(256, 128)#句子提取\n",
    "        self.fc1 = torch.nn.Conv2d(128*4, 128, kernel_size=1, stride=1)\n",
    "        self.fc2 = torch.nn.Conv2d(128, 3, kernel_size=1, stride=1)\n",
    "        # Initializing weights\n",
    "        self.apply(weights_init)\n",
    "        \n",
    "        #self_add\n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "\n",
    "    def cross_modal_comb(self, visual_feat, sentence_embed):\n",
    "        batch_size = visual_feat.size(0)\n",
    "        #print(\"进入交叉阶段,batch_size = \"+str(batch_size))\n",
    "\n",
    "        vv_feature = visual_feat.expand([batch_size,batch_size,self.semantic_size])\n",
    "        ss_feature = sentence_embed.repeat(1,1,batch_size).view(batch_size,batch_size,self.semantic_size)\n",
    "\n",
    "        concat_feature = torch.cat([vv_feature, ss_feature], 2)\n",
    "\n",
    "        mul_feature = vv_feature * ss_feature # 64,64,128\n",
    "        add_feature = vv_feature + ss_feature # 64,64,128\n",
    "\n",
    "        comb_feature = torch.cat([mul_feature, add_feature, concat_feature], 2)\n",
    "\n",
    "        return comb_feature\n",
    "\n",
    "\n",
    "    def forward(self, visual_feature_train, sentence_embed_train):\n",
    "        transformed_clip_train = self.v2s_lt(visual_feature_train)\n",
    "        transformed_clip_train_norm = F.normalize(transformed_clip_train, p=2, dim=1)\n",
    "        \n",
    "        sentence_embed_train = self.embedding(sentence_embed_train)\n",
    "        sentence_embed_train,_ =self.lstm(sentence_embed_train)\n",
    "        transformed_sentence_train = self.s2s_lt(sentence_embed_train[:,-1,:])\n",
    "        transformed_sentence_train_norm = F.normalize(transformed_sentence_train, p=2, dim=1)\n",
    "        \n",
    "        cross_modal_vec_train = self.cross_modal_comb(transformed_clip_train_norm, transformed_sentence_train_norm)\n",
    "        \n",
    "        cross_modal_vec_train = cross_modal_vec_train.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        mid_output = self.fc1(cross_modal_vec_train)\n",
    "        mid_output = F.relu(mid_output)\n",
    "        sim_score_mat_train = self.fc2(mid_output).squeeze(0)\n",
    "        \n",
    "        return sim_score_mat_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_model = TALL()\n",
    "TALL_model.load_state_dict(torch.load(save_path + 'epoch665params.pkl'))\n",
    "lr = 0.01\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "optimizer = torch.optim.Adam(TALL_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(inital_epoch):\n",
    "    # compute alignment and regression loss\n",
    "    Max_loss = 1000\n",
    "    print(\"start traning.......\")\n",
    "    for epoch in range(EPOCH):\n",
    "        train_loss = 0\n",
    "        loss_align_sum = 0\n",
    "        loss_reg_sum = 0\n",
    "        count = 0\n",
    "        batch_train = batch_iter(sentence_tarin_batch, target_train_csv, target_train_list, BATCH_SIZE)\n",
    "        begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        for x_batch, y_csv, target_time in batch_train:\n",
    "            if y_csv.shape[0]==BATCH_SIZE:\n",
    "                count += 1\n",
    "                x = Variable(torch.LongTensor(x_batch))\n",
    "                y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                offsets = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                outputs = TALL_model(y, x)\n",
    "                sim_score_mat = outputs[0]\n",
    "                p_reg_mat = outputs[1]\n",
    "                l_reg_mat = outputs[2]\n",
    "                # loss cls, not considering iou\n",
    "                input_size = outputs.size(1)\n",
    "                I = torch.eye(input_size)\n",
    "                I_2 = -2 * I\n",
    "                all1 = torch.ones(input_size, input_size)\n",
    "\n",
    "                mask_mat = I_2 + all1  \n",
    "\n",
    "                alpha = 1.0 / input_size\n",
    "                lambda_regression = 0.01\n",
    "                batch_para_mat = alpha * all1\n",
    "                para_mat = I + batch_para_mat\n",
    "\n",
    "                loss_mat = torch.log(all1 + torch.exp(mask_mat*sim_score_mat))\n",
    "                loss_mat = loss_mat*para_mat\n",
    "                loss_align = loss_mat.mean()\n",
    "\n",
    "                # regression loss\n",
    "                l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "                p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "                offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "                loss_reg = torch.abs(offset_pred - offsets).mean() # L1 loss\n",
    "\n",
    "                loss= lambda_regression*loss_reg +loss_align\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss\n",
    "                loss_reg_sum += loss_reg\n",
    "                loss_align_sum += loss_align\n",
    "        \n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(begin_time+' | '+current_time+' | '+('Epoch: %d | Loss: %.3f | loss_align: %.3f | loss_reg: %.3f' % (inital_epoch + epoch, train_loss / (count), loss_align_sum / (count), loss_reg_sum / (count))))\n",
    "        train_loss_list.append(train_loss / (count))\n",
    "        \n",
    "        if (epoch + 1)%5 == 0:\n",
    "            print(\"validation.....\")\n",
    "            val_loss = 0\n",
    "            valloss_align_sum = 0\n",
    "            valloss_reg_sum = 0\n",
    "            count = 0\n",
    "            batch_val = batch_iter(sentence_val_batch, target_val_csv, target_val_list, BATCH_SIZE)\n",
    "            begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            for x_batch, y_csv, target_time in batch_val:\n",
    "                if y_csv.shape[0]==BATCH_SIZE:\n",
    "                    count += 1\n",
    "                    x = Variable(torch.LongTensor(x_batch))\n",
    "                    y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                    offsets = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                    outputs = TALL_model(y, x)\n",
    "                    sim_score_mat = outputs[0]\n",
    "                    p_reg_mat = outputs[1]\n",
    "                    l_reg_mat = outputs[2]\n",
    "                    input_size = outputs.size(1)\n",
    "                    I = torch.eye(input_size)\n",
    "                    I_2 = -2 * I\n",
    "                    all1 = torch.ones(input_size, input_size)\n",
    "\n",
    "                    mask_mat = I_2 + all1  \n",
    "\n",
    "                    alpha = 1.0 / input_size\n",
    "                    lambda_regression = 0.01\n",
    "                    batch_para_mat = alpha * all1\n",
    "                    para_mat = I + batch_para_mat\n",
    "\n",
    "                    loss_mat = torch.log(all1 + torch.exp(mask_mat*sim_score_mat))\n",
    "                    loss_mat = loss_mat*para_mat\n",
    "                    loss_align = loss_mat.mean()\n",
    "\n",
    "                    # regression loss\n",
    "                    l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "                    p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "                    offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "                    loss_reg = torch.abs(offset_pred - offsets).mean() # L1 loss\n",
    "\n",
    "                    loss= lambda_regression*loss_reg +loss_align\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    val_loss += loss\n",
    "                    valloss_reg_sum += loss_reg\n",
    "                    valloss_align_sum += loss_align\n",
    "            \n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            print(begin_time+' | '+current_time+' | '+('Epoch: %d | Loss: %.3f | loss_align: %.3f | loss_reg: %.3f' % (inital_epoch + epoch, val_loss / (count), valloss_align_sum / (count), valloss_reg_sum / (count))))\n",
    "            val_loss_list.append(val_loss / (count))\n",
    "            torch.save(TALL_model.state_dict(), save_path + 'epoch'+str(inital_epoch + epoch)+'params.pkl')\n",
    "            if val_loss / count < Max_loss:\n",
    "                Max_loss = val_loss / count\n",
    "                print(\"model save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start traning.......\n",
      "2020-08-15 19:01:41 | 2020-08-15 19:02:51 | Epoch: 665 | Loss: 0.069 | loss_align: 0.000 | loss_reg: 6.935\n",
      "2020-08-15 19:02:51 | 2020-08-15 19:04:06 | Epoch: 666 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.463\n",
      "2020-08-15 19:04:06 | 2020-08-15 19:05:18 | Epoch: 667 | Loss: 0.067 | loss_align: 0.000 | loss_reg: 6.666\n",
      "2020-08-15 19:05:18 | 2020-08-15 19:06:28 | Epoch: 668 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.475\n",
      "2020-08-15 19:06:28 | 2020-08-15 19:07:38 | Epoch: 669 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.345\n",
      "validation.....\n",
      "2020-08-15 19:07:38 | 2020-08-15 19:08:02 | Epoch: 669 | Loss: 0.131 | loss_align: 0.000 | loss_reg: 13.112\n",
      "model save!\n",
      "2020-08-15 19:08:02 | 2020-08-15 19:09:13 | Epoch: 670 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.632\n",
      "2020-08-15 19:09:13 | 2020-08-15 19:10:23 | Epoch: 671 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.620\n",
      "2020-08-15 19:10:23 | 2020-08-15 19:11:34 | Epoch: 672 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.446\n",
      "2020-08-15 19:11:34 | 2020-08-15 19:12:46 | Epoch: 673 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.547\n",
      "2020-08-15 19:12:46 | 2020-08-15 19:13:57 | Epoch: 674 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.396\n",
      "validation.....\n",
      "2020-08-15 19:13:57 | 2020-08-15 19:14:22 | Epoch: 674 | Loss: 0.133 | loss_align: 0.000 | loss_reg: 13.328\n",
      "2020-08-15 19:14:22 | 2020-08-15 19:15:35 | Epoch: 675 | Loss: 0.067 | loss_align: 0.000 | loss_reg: 6.741\n",
      "2020-08-15 19:15:35 | 2020-08-15 19:16:49 | Epoch: 676 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.553\n",
      "2020-08-15 19:16:49 | 2020-08-15 19:18:04 | Epoch: 677 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.424\n",
      "2020-08-15 19:18:04 | 2020-08-15 19:19:21 | Epoch: 678 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.625\n",
      "2020-08-15 19:19:21 | 2020-08-15 19:20:38 | Epoch: 679 | Loss: 0.067 | loss_align: 0.000 | loss_reg: 6.697\n",
      "validation.....\n",
      "2020-08-15 19:20:38 | 2020-08-15 19:21:05 | Epoch: 679 | Loss: 0.128 | loss_align: 0.000 | loss_reg: 12.756\n",
      "model save!\n",
      "2020-08-15 19:21:05 | 2020-08-15 19:22:24 | Epoch: 680 | Loss: 0.067 | loss_align: 0.000 | loss_reg: 6.745\n",
      "2020-08-15 19:22:24 | 2020-08-15 19:23:44 | Epoch: 681 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.383\n",
      "2020-08-15 19:23:44 | 2020-08-15 19:25:09 | Epoch: 682 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.373\n",
      "2020-08-15 19:25:09 | 2020-08-15 19:26:31 | Epoch: 683 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.424\n",
      "2020-08-15 19:26:31 | 2020-08-15 19:27:55 | Epoch: 684 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.409\n",
      "validation.....\n",
      "2020-08-15 19:27:55 | 2020-08-15 19:28:22 | Epoch: 684 | Loss: 0.130 | loss_align: 0.000 | loss_reg: 13.024\n",
      "2020-08-15 19:28:22 | 2020-08-15 19:29:44 | Epoch: 685 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.631\n",
      "2020-08-15 19:29:44 | 2020-08-15 19:31:09 | Epoch: 686 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.588\n",
      "2020-08-15 19:31:09 | 2020-08-15 19:32:34 | Epoch: 687 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.644\n",
      "2020-08-15 19:32:34 | 2020-08-15 19:33:57 | Epoch: 688 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.257\n",
      "2020-08-15 19:33:57 | 2020-08-15 19:35:19 | Epoch: 689 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.535\n",
      "validation.....\n",
      "2020-08-15 19:35:19 | 2020-08-15 19:35:46 | Epoch: 689 | Loss: 0.126 | loss_align: 0.000 | loss_reg: 12.579\n",
      "model save!\n",
      "2020-08-15 19:35:46 | 2020-08-15 19:37:07 | Epoch: 690 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.604\n",
      "2020-08-15 19:37:07 | 2020-08-15 19:38:25 | Epoch: 691 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.322\n",
      "2020-08-15 19:38:25 | 2020-08-15 19:39:43 | Epoch: 692 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.208\n",
      "2020-08-15 19:39:43 | 2020-08-15 19:41:01 | Epoch: 693 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.441\n",
      "2020-08-15 19:41:01 | 2020-08-15 19:42:21 | Epoch: 694 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.525\n",
      "validation.....\n",
      "2020-08-15 19:42:21 | 2020-08-15 19:42:48 | Epoch: 694 | Loss: 0.129 | loss_align: 0.000 | loss_reg: 12.869\n",
      "2020-08-15 19:42:48 | 2020-08-15 19:44:12 | Epoch: 695 | Loss: 0.067 | loss_align: 0.000 | loss_reg: 6.722\n",
      "2020-08-15 19:44:12 | 2020-08-15 19:45:36 | Epoch: 696 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.277\n",
      "2020-08-15 19:45:36 | 2020-08-15 19:46:56 | Epoch: 697 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.195\n",
      "2020-08-15 19:46:56 | 2020-08-15 19:48:33 | Epoch: 698 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.446\n",
      "2020-08-15 19:48:33 | 2020-08-15 19:50:00 | Epoch: 699 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.307\n",
      "validation.....\n",
      "2020-08-15 19:50:00 | 2020-08-15 19:50:27 | Epoch: 699 | Loss: 0.129 | loss_align: 0.000 | loss_reg: 12.882\n",
      "2020-08-15 19:50:27 | 2020-08-15 19:51:50 | Epoch: 700 | Loss: 0.068 | loss_align: 0.000 | loss_reg: 6.765\n",
      "2020-08-15 19:51:50 | 2020-08-15 19:53:13 | Epoch: 701 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.225\n",
      "2020-08-15 19:53:13 | 2020-08-15 19:54:39 | Epoch: 702 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.280\n",
      "2020-08-15 19:54:39 | 2020-08-15 19:56:03 | Epoch: 703 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.184\n",
      "2020-08-15 19:56:03 | 2020-08-15 19:57:32 | Epoch: 704 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.342\n",
      "validation.....\n",
      "2020-08-15 19:57:32 | 2020-08-15 19:58:01 | Epoch: 704 | Loss: 0.130 | loss_align: 0.000 | loss_reg: 13.024\n",
      "2020-08-15 19:58:01 | 2020-08-15 19:59:27 | Epoch: 705 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.266\n",
      "2020-08-15 19:59:27 | 2020-08-15 20:00:53 | Epoch: 706 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.228\n",
      "2020-08-15 20:00:53 | 2020-08-15 20:02:18 | Epoch: 707 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.439\n",
      "2020-08-15 20:02:18 | 2020-08-15 20:03:49 | Epoch: 708 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.147\n",
      "2020-08-15 20:03:49 | 2020-08-15 20:05:25 | Epoch: 709 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.217\n",
      "validation.....\n",
      "2020-08-15 20:05:25 | 2020-08-15 20:05:56 | Epoch: 709 | Loss: 0.120 | loss_align: 0.000 | loss_reg: 11.960\n",
      "model save!\n",
      "2020-08-15 20:05:56 | 2020-08-15 20:07:30 | Epoch: 710 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.531\n",
      "2020-08-15 20:07:30 | 2020-08-15 20:08:58 | Epoch: 711 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 6.040\n",
      "2020-08-15 20:08:58 | 2020-08-15 20:10:27 | Epoch: 712 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.264\n",
      "2020-08-15 20:10:27 | 2020-08-15 20:11:56 | Epoch: 713 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.264\n",
      "2020-08-15 20:11:56 | 2020-08-15 20:13:26 | Epoch: 714 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.452\n",
      "validation.....\n",
      "2020-08-15 20:13:26 | 2020-08-15 20:13:56 | Epoch: 714 | Loss: 0.128 | loss_align: 0.000 | loss_reg: 12.818\n",
      "2020-08-15 20:13:56 | 2020-08-15 20:15:28 | Epoch: 715 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.452\n",
      "2020-08-15 20:15:28 | 2020-08-15 20:16:57 | Epoch: 716 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.229\n",
      "2020-08-15 20:16:57 | 2020-08-15 20:18:28 | Epoch: 717 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 5.973\n",
      "2020-08-15 20:18:28 | 2020-08-15 20:20:01 | Epoch: 718 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.355\n",
      "2020-08-15 20:20:01 | 2020-08-15 20:21:32 | Epoch: 719 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.080\n",
      "validation.....\n",
      "2020-08-15 20:21:32 | 2020-08-15 20:22:02 | Epoch: 719 | Loss: 0.116 | loss_align: 0.000 | loss_reg: 11.589\n",
      "model save!\n",
      "2020-08-15 20:22:02 | 2020-08-15 20:23:34 | Epoch: 720 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.322\n",
      "2020-08-15 20:23:34 | 2020-08-15 20:25:07 | Epoch: 721 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.272\n",
      "2020-08-15 20:25:07 | 2020-08-15 20:26:40 | Epoch: 722 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.408\n",
      "2020-08-15 20:26:40 | 2020-08-15 20:28:21 | Epoch: 723 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.053\n",
      "2020-08-15 20:28:21 | 2020-08-15 20:29:57 | Epoch: 724 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.244\n",
      "validation.....\n",
      "2020-08-15 20:29:57 | 2020-08-15 20:30:29 | Epoch: 724 | Loss: 0.124 | loss_align: 0.000 | loss_reg: 12.437\n",
      "2020-08-15 20:30:29 | 2020-08-15 20:32:04 | Epoch: 725 | Loss: 0.064 | loss_align: 0.000 | loss_reg: 6.361\n",
      "2020-08-15 20:32:04 | 2020-08-15 20:33:43 | Epoch: 726 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.256\n",
      "2020-08-15 20:33:43 | 2020-08-15 20:35:20 | Epoch: 727 | Loss: 0.058 | loss_align: 0.000 | loss_reg: 5.805\n",
      "2020-08-15 20:35:20 | 2020-08-15 20:36:58 | Epoch: 728 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.170\n",
      "2020-08-15 20:36:58 | 2020-08-15 20:38:35 | Epoch: 729 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.254\n",
      "validation.....\n",
      "2020-08-15 20:38:35 | 2020-08-15 20:39:09 | Epoch: 729 | Loss: 0.122 | loss_align: 0.000 | loss_reg: 12.212\n",
      "2020-08-15 20:39:09 | 2020-08-15 20:40:48 | Epoch: 730 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.483\n",
      "2020-08-15 20:40:48 | 2020-08-15 20:42:27 | Epoch: 731 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.260\n",
      "2020-08-15 20:42:27 | 2020-08-15 20:44:11 | Epoch: 732 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.326\n",
      "2020-08-15 20:44:11 | 2020-08-15 20:45:52 | Epoch: 733 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.265\n",
      "2020-08-15 20:45:52 | 2020-08-15 20:47:33 | Epoch: 734 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 5.993\n",
      "validation.....\n",
      "2020-08-15 20:47:33 | 2020-08-15 20:48:06 | Epoch: 734 | Loss: 0.129 | loss_align: 0.000 | loss_reg: 12.853\n",
      "2020-08-15 20:48:06 | 2020-08-15 20:49:50 | Epoch: 735 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.466\n",
      "2020-08-15 20:49:50 | 2020-08-15 20:51:31 | Epoch: 736 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.196\n",
      "2020-08-15 20:51:31 | 2020-08-15 20:53:24 | Epoch: 737 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 5.984\n",
      "2020-08-15 20:53:24 | 2020-08-15 20:55:12 | Epoch: 738 | Loss: 0.063 | loss_align: 0.000 | loss_reg: 6.278\n",
      "2020-08-15 20:55:12 | 2020-08-15 20:56:54 | Epoch: 739 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.133\n",
      "validation.....\n",
      "2020-08-15 20:56:54 | 2020-08-15 20:57:28 | Epoch: 739 | Loss: 0.121 | loss_align: 0.000 | loss_reg: 12.106\n",
      "2020-08-15 20:57:28 | 2020-08-15 20:59:31 | Epoch: 740 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.175\n",
      "2020-08-15 20:59:31 | 2020-08-15 21:01:34 | Epoch: 741 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.103\n",
      "2020-08-15 21:01:34 | 2020-08-15 21:03:34 | Epoch: 742 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.187\n",
      "2020-08-15 21:03:34 | 2020-08-15 21:05:47 | Epoch: 743 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.054\n",
      "2020-08-15 21:05:47 | 2020-08-15 21:07:36 | Epoch: 744 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.104\n",
      "validation.....\n",
      "2020-08-15 21:07:36 | 2020-08-15 21:08:11 | Epoch: 744 | Loss: 0.115 | loss_align: 0.000 | loss_reg: 11.519\n",
      "model save!\n",
      "2020-08-15 21:08:11 | 2020-08-15 21:10:01 | Epoch: 745 | Loss: 0.066 | loss_align: 0.000 | loss_reg: 6.623\n",
      "2020-08-15 21:10:01 | 2020-08-15 21:12:01 | Epoch: 746 | Loss: 0.059 | loss_align: 0.000 | loss_reg: 5.864\n",
      "2020-08-15 21:12:01 | 2020-08-15 21:14:24 | Epoch: 747 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.079\n",
      "2020-08-15 21:14:24 | 2020-08-15 21:16:19 | Epoch: 748 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.071\n",
      "2020-08-15 21:16:19 | 2020-08-15 21:18:17 | Epoch: 749 | Loss: 0.062 | loss_align: 0.000 | loss_reg: 6.152\n",
      "validation.....\n",
      "2020-08-15 21:18:17 | 2020-08-15 21:19:00 | Epoch: 749 | Loss: 0.114 | loss_align: 0.000 | loss_reg: 11.404\n",
      "model save!\n",
      "2020-08-15 21:19:00 | 2020-08-15 21:21:03 | Epoch: 750 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.112\n",
      "2020-08-15 21:21:03 | 2020-08-15 21:22:54 | Epoch: 751 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 6.004\n",
      "2020-08-15 21:22:54 | 2020-08-15 21:24:58 | Epoch: 752 | Loss: 0.059 | loss_align: 0.000 | loss_reg: 5.931\n",
      "2020-08-15 21:24:58 | 2020-08-15 21:27:01 | Epoch: 753 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.078\n",
      "2020-08-15 21:27:01 | 2020-08-15 21:29:08 | Epoch: 754 | Loss: 0.061 | loss_align: 0.000 | loss_reg: 6.069\n",
      "validation.....\n",
      "2020-08-15 21:29:08 | 2020-08-15 21:29:49 | Epoch: 754 | Loss: 0.112 | loss_align: 0.000 | loss_reg: 11.185\n",
      "model save!\n",
      "2020-08-15 21:29:49 | 2020-08-15 21:31:45 | Epoch: 755 | Loss: 0.065 | loss_align: 0.000 | loss_reg: 6.455\n",
      "2020-08-15 21:31:45 | 2020-08-15 21:33:42 | Epoch: 756 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 5.993\n",
      "2020-08-15 21:33:42 | 2020-08-15 21:35:40 | Epoch: 757 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 5.992\n",
      "2020-08-15 21:35:40 | 2020-08-15 21:37:39 | Epoch: 758 | Loss: 0.060 | loss_align: 0.000 | loss_reg: 6.029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3b1cb9e3fee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m665\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-25b5ac705c0a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(inital_epoch)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mloss_reg_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(665)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(train_loss_list, val_loss_list):\n",
    "    x1 = range(0, len(train_loss_list))\n",
    "    x2 = range(0, len(val_loss_list))\n",
    "    #with plt.style.context(['science']):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, train_loss_list[:len(train_loss_list)], 'o-')\n",
    "    plt.title('train loss vs. epoches')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2,val_loss_list[:len(val_loss_list)] , '.-')\n",
    "    plt.xlabel('Val loss vs. epoches')\n",
    "    plt.ylabel('Val loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_list, val_loss_list)\n",
    "torch.save(TALL_model.state_dict(), save_path + 'final_model_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        #self.rnn = nn.GRU(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        self.f1 = nn.Sequential(nn.Linear(256,128),\n",
    "                                nn.Dropout(0.8),\n",
    "                                nn.ReLU())\n",
    "\n",
    "        self.f2 = nn.Sequential(nn.Linear(128,64))\n",
    "        \n",
    "        \n",
    "        self.conv1=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1,10,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "        \n",
    "        self.conv2=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(10,20,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "\n",
    "        #self.fc1=torch.nn.Linear(2520,128)\n",
    "        self.fc1=torch.nn.Linear(512,128)\n",
    "        self.fc1_drop=torch.nn.Dropout(p=0.4)\n",
    "        self.fc2=torch.nn.Linear(128, 64)\n",
    "        \n",
    "        #特征融合\n",
    "        self.final_fc = nn.Linear(in_features=128, out_features=64)\n",
    "        self.score_fc = torch.nn.Conv2d(64,3,kernel_size=1,stride=1)\n",
    "        \n",
    "        \n",
    "    def cnnout(self, x2):\n",
    "        in_fc=x2.view(x2.size(0),-1)\n",
    "        out_fc1=self.fc1(in_fc)\n",
    "        out_drop=self.fc1_drop(out_fc1)\n",
    "        out_fc2=self.fc2(out_drop)\n",
    "        return out_fc2\n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        if x1.shape[0]!=2:\n",
    "            #lstm\n",
    "            x = self.embedding(x1)\n",
    "            x,_ = self.rnn(x)\n",
    "            x = F.dropout(x,p=0.8)\n",
    "            \n",
    "            x = self.f1(x[:,-1,:])\n",
    "            lstm_output = self.f2(x)\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            #concat\n",
    "            output = torch.cat((lstm_output, cnn_out), 1)\n",
    "            output = self.final_fc(output)\n",
    "            return output\n",
    "        else:\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            return cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class Change(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Change, self).__init__()\n",
    "        #特征融合\n",
    "        self.score_fc = torch.nn.Conv1d(64, 2, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = x#[10, 64]\n",
    "        output = output.unsqueeze(2)\n",
    "        score = self.score_fc(output)\n",
    "        offset_pred = score.squeeze(2)\n",
    "        return offset_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Change:\n\tsize mismatch for score_fc.weight: copying a param with shape torch.Size([2, 128, 1]) from checkpoint, the shape in current model is torch.Size([2, 64, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-083e13f0d4fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTALL_final_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/wuxun/Desktop/Data/TALL/save_model/epoch754params.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmiddle_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_64_dim_params.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/513.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 769\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Change:\n\tsize mismatch for score_fc.weight: copying a param with shape torch.Size([2, 128, 1]) from checkpoint, the shape in current model is torch.Size([2, 64, 1])."
     ]
    }
   ],
   "source": [
    "TALL_final_model = TALL()\n",
    "My_model = Change()\n",
    "middle_model = LSTM_CNN()\n",
    "TALL_final_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/TALL/save_model/epoch754params.pkl'))\n",
    "middle_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_64_dim_params.pkl'))\n",
    "My_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/513.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 固定模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TALL(\n",
       "  (v2s_lt): Linear(in_features=1536, out_features=128, bias=True)\n",
       "  (s2s_lt): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc2): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (embedding): Embedding(5000, 64)\n",
       "  (lstm): LSTM(64, 128, num_layers=2, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_model.eval()\n",
    "middle_model.eval()\n",
    "TALL_final_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IoU_thresh = [0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_IoU(i0, i1):\n",
    "    # calculate temporal intersection over union\n",
    "    union = (min(i0[0], i1[0]), max(i0[1], i1[1]))\n",
    "    inter = (max(i0[0], i1[0]), min(i0[1], i1[1]))\n",
    "    iou = 1.0*(inter[1]-inter[0])/(union[1]-union[0])\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_IoU_recall_top_n_forreg(iou_thresh, time_mat, time_pre_mat):#top\n",
    "    correct_num = 0\n",
    "    for i in range(time_mat.shape[0]):\n",
    "        gt_start = time_mat[i][0]\n",
    "        gt_end = time_mat[i][1]\n",
    "        pred_start = time_pre_mat[i][0]\n",
    "        pred_end = time_pre_mat[i][1]\n",
    "        iou = calculate_IoU((gt_start, gt_end),(pred_start, pred_end))\n",
    "        if iou>=iou_thresh:\n",
    "            correct_num+=1\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_for_TALL(outputs):\n",
    "    p_reg_mat = outputs[1]\n",
    "    l_reg_mat = outputs[2]\n",
    "    input_size = outputs.size(1)\n",
    "    I = torch.eye(input_size)\n",
    "    l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "    p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "    offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "    return offset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取test数据集\n",
    "def get_test_dict_for_TALL(path, csv_path):\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    csv=[]\n",
    "    time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[5].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end)//2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time/time_length*500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            #上下文信息\n",
    "            target_frame_start = int(cur_start/time_length*500)\n",
    "            target_frame_end = int(cur_end/time_length*500)\n",
    "            if target_frame_start == target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num - 3, 0)\n",
    "            if  target_frame_end ==target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num + 3, 499)\n",
    "                \n",
    "            pre_context = np.zeros([target_frame_num - target_frame_start, 512], dtype=np.float32)\n",
    "            post_context = np.zeros([target_frame_end - target_frame_num, 512], dtype=np.float32) \n",
    "            for i in range(target_frame_num - target_frame_start):\n",
    "                pre_context[i] = frame_sum.loc[i]\n",
    "                \n",
    "            for i in range(target_frame_end - target_frame_num):\n",
    "                post_context[i] = frame_sum.loc[i]\n",
    "            \n",
    "            #对pre_context和post_context取均值\n",
    "            pre_context = np.mean(pre_context, axis=0)\n",
    "            post_context = np.mean(post_context, axis=0)\n",
    "            \n",
    "            #对三段信息进行拼接\n",
    "            image = np.hstack((pre_context, target_middle_frame, post_context))\n",
    "            \n",
    "            csv.append(image)\n",
    "            time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(csv),len(time_list))\n",
    "    \n",
    "    return batch_seq, csv, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取test集\n",
    "# 读取test数据集\n",
    "def get_test_dict_for_My_model(path, csv_path):\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    csv=[]\n",
    "    time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end)//2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time/time_length*500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            csv.append(target_middle_frame)\n",
    "            time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(csv),len(time_list))\n",
    "    \n",
    "    return batch_seq, csv, time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取test集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894.0  896.0 1106.12\n",
      "出现重复！\n",
      "132 132 132\n"
     ]
    }
   ],
   "source": [
    "TALL_test_seq, TALL_test_csv, TALL_test_time_list = get_test_dict_for_TALL(test_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My_test_seq, My_test_csv, My_test_time_list = get_test_dict_for_My_model(test_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TALL计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor(TALL_test_seq))\n",
    "y = Variable(torch.FloatTensor(np.array(TALL_test_csv)))\n",
    "TALL_time_mat = Variable(torch.FloatTensor(np.array(TALL_test_time_list)))\n",
    "TALL_outputs = TALL_final_model(y, x)\n",
    "TALL_pre_time_mat = pred_for_TALL(TALL_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TALL: R@1 for iou_thresh: 0.1 is : 0.114\n",
      "TALL: R@1 for iou_thresh: 0.3 is : 0.076\n",
      "TALL: R@1 for iou_thresh: 0.5 is : 0.015\n",
      "TALL: R@1 for iou_thresh: 0.7 is : 0.000\n"
     ]
    }
   ],
   "source": [
    "for iou_thresh in IoU_thresh:\n",
    "    corrnum = compute_IoU_recall_top_n_forreg(iou_thresh, TALL_time_mat, TALL_pre_time_mat)\n",
    "    corr_avg = corrnum*1.0 / TALL_time_mat.shape[0] \n",
    "    print(\"TALL: R@1 for iou_thresh: %.1f is : %.3f\" % (iou_thresh, corr_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My_model计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor(My_test_seq))\n",
    "y = Variable(torch.FloatTensor(np.array(My_test_csv)))\n",
    "My_time_mat = Variable(torch.FloatTensor(np.array(My_test_time_list)))\n",
    "My_output1 = middle_model(x, y)\n",
    "My_pred_time_mat = My_model(My_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_model: R@1 for iou_thresh: 0.1 is : 0.114\n",
      "My_model: R@1 for iou_thresh: 0.3 is : 0.038\n",
      "My_model: R@1 for iou_thresh: 0.5 is : 0.015\n",
      "My_model: R@1 for iou_thresh: 0.7 is : 0.000\n"
     ]
    }
   ],
   "source": [
    "for iou_thresh in IoU_thresh:\n",
    "    corrnum = compute_IoU_recall_top_n_forreg(iou_thresh, My_time_mat, My_pred_time_mat)\n",
    "    corr_avg = corrnum*1.0 / My_time_mat.shape[0] \n",
    "    print(\"My_model: R@1 for iou_thresh: %.1f is : %.3f\" % (iou_thresh, corr_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
