{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入相应的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime  # 用于计算时间\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#import tensorflow.contrib.keras as kr\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from torchtext import data\n",
    "import jieba\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=15)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_path = 'C:/Users/wuxun/Desktop/Data/feat_dat/'\n",
    "image_path = 'C:/Users/wuxun/Desktop/Data/image/'#存储到image文件夹中\n",
    "clip_path = 'C:/Users/wuxun/Desktop/Data/clip/'\n",
    "text_dir = 'C:/Users/wuxun/Desktop/Data/clear_text.txt'\n",
    "vocab_dir = 'C:/Users/wuxun/Desktop/Data/vocab.txt'\n",
    "train_path = 'C:/Users/wuxun/Desktop/Data/training/training.txt'\n",
    "val_path = 'C:/Users/wuxun/Desktop/Data/validation/validation.txt'\n",
    "csv_path = 'D:/csv/'\n",
    "save_path = 'C:/Users/wuxun/Desktop/Data/save_model/'\n",
    "save_path2 = 'C:/Users/wuxun/Desktop/Data/save_model2/params.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#固定随机数种子\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def read_file(filename):\n",
    "\n",
    "    \"\"\"读取文件数据\"\"\"\n",
    "    \n",
    "    contents = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            contents.append(re.split('[, \\n.]',line))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(text_dir, vocab_dir, vocab_size=3000):\n",
    "\n",
    "    \"\"\"根据训练集构建词汇表，存储\"\"\"\n",
    "    data_train = read_file(text_dir)\n",
    "    all_data = []\n",
    "    for content in data_train:\n",
    "        for k in content:\n",
    "            if len(k)!=0:\n",
    "                all_data.append(k)\n",
    "    print(all_data)\n",
    "    counter = Counter(all_data)\n",
    "    count_pairs = counter.most_common(vocab_size - 1)\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    # 添加一个 <PAD> 来将所有文本pad为同一长度\n",
    "    words = ['<PAD>'] + list(words)\n",
    "    open(vocab_dir, mode='w').write('\\n'.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(vocab_dir):\n",
    "\n",
    "    \"\"\"读取词汇表\"\"\"\n",
    "\n",
    "    with open(vocab_dir) as fp:\n",
    "        words = [(_.strip()) for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_words(content, words):\n",
    "\n",
    "    \"\"\"将id表示的内容转换为文字\"\"\"\n",
    "\n",
    "    return ''.join(words[x] for x in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(path, csv_path):\n",
    "    '''\n",
    "    获得最终的数据集\n",
    "    path:文本数据集\n",
    "    csv_path\n",
    "    '''\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    source_csv=[]\n",
    "    target_csv=[]\n",
    "    fake_time_list=[]\n",
    "    source_time_list=[]\n",
    "    target_time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            source = List[4]\n",
    "            target = List[5]\n",
    "            fake_time = (List[7].split('_'))\n",
    "            fake_time_l=int(fake_time[0])\n",
    "            fake_time_r=int(fake_time[1])\n",
    "            fake_time_list.append([fake_time_l, fake_time_r])\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点\n",
    "            source = source.split('_')\n",
    "            target = target.split('_')\n",
    "            \n",
    "            source_time = (float(source[0])+float(source[1]))//2\n",
    "            source_time_list.append([float(source[0]),float(source[1])])\n",
    "            source_frame_num = int(source_time/time_length*500)\n",
    "            source_frame = frame_sum.loc[source_frame_num]\n",
    "            source_csv.append([source_frame])\n",
    "            \n",
    "            target_time = (float(target[0])+float(target[1]))//2\n",
    "            target_time_list.append([float(target[0]),float(target[1])])\n",
    "            target_frame_num = int(target_time/time_length*500)\n",
    "            target_frame = frame_sum.loc[target_frame_num]\n",
    "            target_csv.append([target_frame])\n",
    "            \n",
    "            #添加其余帧数据作为对抗样本\n",
    "            fake_time = (fake_time_l + fake_time_r)//2\n",
    "            fake_time_num = int(fake_time/time_length*500)\n",
    "            #print(str(count)+\"     \"+str(fake_time_num))\n",
    "            fake_frame = frame_sum.loc[fake_time_num]\n",
    "            #补充数据\n",
    "            source_csv.append([source_frame])\n",
    "            data_id.append(sentence_id)\n",
    "            target_csv.append([fake_frame])\n",
    "            source_time_list.append([float(source[0]),float(source[1])])\n",
    "            target_time_list.append([fake_time_l, fake_time_r])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)\n",
    "            \n",
    "    print(len(batch_seq),len(source_csv),len(target_csv))\n",
    "    \n",
    "    return batch_seq, source_csv, target_csv, source_time_list, target_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096 3096 3096\n"
     ]
    }
   ],
   "source": [
    "#训练集\n",
    "x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train = get_dict(train_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046 1046 1046\n"
     ]
    }
   ],
   "source": [
    "#验证集\n",
    "x_batch_val, x_csv_val, y_csv_val, source_list_val, target_list_val = get_dict(val_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lamba = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        #self.rnn = nn.GRU(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        self.f1 = nn.Sequential(nn.Linear(256,128),\n",
    "                                nn.Dropout(0.8),\n",
    "                                nn.ReLU())\n",
    "\n",
    "        self.f2 = nn.Sequential(nn.Linear(128,64))\n",
    "        \n",
    "        \n",
    "        self.conv1=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1,10,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "        \n",
    "        self.conv2=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(10,20,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "\n",
    "        #self.fc1=torch.nn.Linear(2520,128)\n",
    "        self.fc1=torch.nn.Linear(512,128)\n",
    "        self.fc1_drop=torch.nn.Dropout(p=0.4)\n",
    "        self.fc2=torch.nn.Linear(128, 64)\n",
    "        \n",
    "        #特征融合\n",
    "        self.final_fc = nn.Linear(in_features=128, out_features=64)\n",
    "        self.score_fc = torch.nn.Conv2d(64,3,kernel_size=1,stride=1)\n",
    "        \n",
    "        \n",
    "    def cnnout(self, x2):\n",
    "        in_fc=x2.view(x2.size(0),-1)\n",
    "        out_fc1=self.fc1(in_fc)\n",
    "        out_drop=self.fc1_drop(out_fc1)\n",
    "        out_fc2=self.fc2(out_drop)\n",
    "        return out_fc2\n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        if x1.shape[0]!=2:\n",
    "            #lstm\n",
    "            x = self.embedding(x1)\n",
    "            x,_ = self.rnn(x)\n",
    "            x = F.dropout(x,p=0.8)\n",
    "            \n",
    "            x = self.f1(x[:,-1,:])\n",
    "            lstm_output = self.f2(x)\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            #concat\n",
    "            output = torch.cat((lstm_output, cnn_out), 1)\n",
    "            output = self.final_fc(output)\n",
    "            return output\n",
    "        else:\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            return cnn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成批次数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(x_batch, x_csv, y_csv, source_list, target_list, batch_size=32):\n",
    "\n",
    "    \"\"\"\n",
    "    生成批次数据\n",
    "    \"\"\"\n",
    "\n",
    "    data_len = x_batch.shape[0]\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_batch_shuffle = x_batch[indices]\n",
    "    x_csv_shuffle =np.array(x_csv)[indices]\n",
    "    y_csv_shuffle = np.array(y_csv)[indices]\n",
    "    source_list = np.array(source_list)[indices]\n",
    "    target_list = np.array(target_list)[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_batch_shuffle[start_id:end_id], x_csv_shuffle[start_id:end_id], y_csv_shuffle[start_id:end_id], source_list[start_id:end_id], target_list[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储loss数据\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = LSTM_CNN()\n",
    "    #model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/110epoch_20200713_params.pkl'))\n",
    "    Loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    T=Variable(torch.FloatTensor([[1.0,1.0],[1.0,1.0]]))\n",
    "    best_val_loss = 1000000\n",
    "    print(\"train begin......\")\n",
    "\n",
    "    for epoch in range(100):\n",
    "        batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, batch_size)\n",
    "        print(\"====================  epoch:\"+str(epoch)+\"  ========================\")\n",
    "        train_loss_sum = 0\n",
    "        train_loss_avg = 0\n",
    "        count = 0\n",
    "        for x_batch, x_csv, y_csv, source_time, target_time in batch_train:\n",
    "            if x_csv.shape[0]==batch_size:\n",
    "                count += 1\n",
    "                x1 = Variable(torch.LongTensor(x_batch))\n",
    "                x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                pred_y = model(x1, x2)\n",
    "                negtive = model(T, x2)\n",
    "                postive = model(T, y)\n",
    "                loss_reg = Loss(pred_y, postive, negtive)\n",
    "                train_loss_sum += loss_reg\n",
    "                optimizer.zero_grad()\n",
    "                loss_reg.backward()\n",
    "                #nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                optimizer.step()\n",
    "                \n",
    "        train_loss_avg = train_loss_sum /count\n",
    "        print(\"train_loss: \"+str(train_loss_sum))\n",
    "        train_loss_list.append(train_loss_sum)\n",
    "\n",
    "        #对模型进行验证：\n",
    "        if (epoch+1)%5 == 0:\n",
    "            print(\"进行验证.....\")\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            val_loss_avg = 0\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size)\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                if x_csv.shape[0]==batch_size:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                    pred_y = model(x1, x2)\n",
    "                    negtive = model(T, x2)\n",
    "                    postive = model(T, y)\n",
    "                    loss_reg = Loss(pred_y, postive, negtive)\n",
    "                    #loss_reg = torch.abs(pred_y - postive).mean()\n",
    "                    val_loss_sum += loss_reg\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    #nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            val_loss_avg = val_loss_sum /count\n",
    "            print(\"val_loss: \"+str(val_loss_sum))\n",
    "            val_loss_list.append(val_loss_sum)   \n",
    "            torch.save(model.state_dict(), save_path+str(epoch)+'_not_better_params.pkl')\n",
    "            if val_loss_sum < best_val_loss:\n",
    "                torch.save(model.state_dict(), save_path+str(epoch)+'_better_params.pkl')\n",
    "                best_val_loss = val_loss_sum\n",
    "                print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 绘制Loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(train_loss_list, val_loss_list):\n",
    "    x1 = range(0, len(train_loss_list))\n",
    "    x2 = range(0, len(val_loss_list))\n",
    "    #with plt.style.context(['science']):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, train_loss_list[:len(train_loss_list)], 'o-')\n",
    "    plt.title('train loss vs. epoches')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2,val_loss_list[:len(val_loss_list)] , '.-')\n",
    "    plt.xlabel('Val loss vs. epoches')\n",
    "    plt.ylabel('Val loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw(train_loss_list, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#超参数lambda\n",
    "lamba = 0.2\n",
    "batch_size2=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class Change(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Change, self).__init__()\n",
    "        #特征融合\n",
    "        self.score_fc = torch.nn.Conv1d(64, 2, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = x#[10, 64]\n",
    "        output = output.unsqueeze(2)\n",
    "        score = self.score_fc(output)\n",
    "        offset_pred = score.squeeze(2)\n",
    "        return offset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target.shape: torch.Size([10, 2])\n",
      "tensor([[132., 138.],\n",
      "        [ 38.,  76.],\n",
      "        [173., 174.],\n",
      "        [ 46.,  92.],\n",
      "        [175., 193.],\n",
      "        [530., 698.],\n",
      "        [600., 618.],\n",
      "        [193., 386.],\n",
      "        [269., 319.],\n",
      "        [572., 698.]])\n",
      "pred2.shape: torch.Size([10, 2])\n",
      "tensor([[ 10.492096900939941, -25.463617324829102],\n",
      "        [ 10.588456153869629, -22.233877182006836],\n",
      "        [ 12.897061347961426, -22.459053039550781],\n",
      "        [-10.064876556396484,   1.429924845695496],\n",
      "        [ 12.114373207092285, -18.420812606811523],\n",
      "        [  7.368268013000488, -15.004589080810547],\n",
      "        [-23.836320877075195,  -9.423895835876465],\n",
      "        [  4.834786415100098, -53.555286407470703],\n",
      "        [  6.708497047424316, -29.200901031494141],\n",
      "        [ -4.756270408630371, -13.690704345703125]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor(151042.531250000000000, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_CNN()\n",
    "Loss = nn.MSELoss()\n",
    "model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_64_dim_params.pkl'))\n",
    "x1 = Variable(torch.LongTensor(x_batch_train[:10]))\n",
    "x2 = Variable(torch.FloatTensor(x_csv_train[:10]))\n",
    "x3 = Variable(torch.FloatTensor(target_list_train[:10]))\n",
    "print(\"target.shape: \"+str(x3.shape))\n",
    "print(x3)\n",
    "y = Variable(torch.FloatTensor(y_csv_train[:10]))\n",
    "pred = model(x1, x2)\n",
    "change_model = Change()\n",
    "pred2 = change_model(pred)\n",
    "print(\"pred2.shape: \"+str(pred2.shape))\n",
    "print(pred2)\n",
    "loss = Loss(pred2, x3)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_2_list=[]\n",
    "val_loss_2_list=[]\n",
    "resualt_text_path='C:/Users/wuxun/Desktop/resualt.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_2(optimizer, change_model, scheduler):\n",
    "    model = LSTM_CNN()\n",
    "    Loss = nn.MSELoss()\n",
    "    model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_64_dim_params.pkl'))\n",
    "    best_val_loss_2 = 1000000\n",
    "    print(\"train begin......\")\n",
    "    with open(resualt_text_path,'a') as f:\n",
    "        for epoch in range(200):\n",
    "            batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, batch_size2)\n",
    "            count = 0\n",
    "            train_loss_sum = 0\n",
    "            train_loss_avg = 0\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_train:\n",
    "                if x_csv.shape[0]==batch_size2:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                    target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "\n",
    "                    pred = model(x1, x2)\n",
    "                    pred2 = change_model(pred)\n",
    "                    \n",
    "                    loss_reg = torch.sqrt(Loss(pred2, target_time))\n",
    "                    train_loss_sum +=loss_reg\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            #scheduler.step()\n",
    "            train_loss_avg = train_loss_sum /count\n",
    "            print(\"[epoch: \"+str(epoch)+\" ]   loss= \"+str(train_loss_avg)+\" lr = %f\" % (optimizer.param_groups[0]['lr']))\n",
    "            train_loss_2_list.append(train_loss_avg)\n",
    "\n",
    "            if (epoch+1)%5==0:\n",
    "                print(\"进行验证.......\")\n",
    "                batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size2)\n",
    "                count = 0\n",
    "                val_loss_sum = 0\n",
    "                val_loss_avg = 0 \n",
    "                for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                    if x_csv.shape[0]==batch_size2:\n",
    "                        count += 1\n",
    "                        x1 = Variable(torch.LongTensor(x_batch))\n",
    "                        x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                        source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                        target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "\n",
    "                        pred = model(x1, x2)\n",
    "                        pred2 = change_model(pred)\n",
    "                        loss_reg = torch.sqrt(Loss(pred2, target_time))\n",
    "\n",
    "                        val_loss_sum +=loss_reg\n",
    "                        optimizer.zero_grad()\n",
    "                        loss_reg.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                #scheduler.step()\n",
    "                val_loss_avg = val_loss_sum / count\n",
    "                print(\"[epoch: \"+str(epoch)+\" ]   loss= \"+str(val_loss_avg)+\" lr = %f\" % (optimizer.param_groups[0]['lr']))\n",
    "                val_loss_2_list.append(val_loss_avg) \n",
    "                torch.save(change_model.state_dict(), 'C:/Users/wuxun/Desktop/Data/save_model2/epoch'+str(epoch)+'_batchsize1_params.pkl')\n",
    "                if val_loss_avg < best_val_loss_2:\n",
    "                    torch.save(change_model.state_dict(), save_path2)\n",
    "                    best_val_loss_2 = val_loss_avg\n",
    "                    print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率调整策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, lr_policy):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "        Parameters:\n",
    "        optimizer -- 网络优化器\n",
    "        opt.lr_policy -- 学习率scheduler的名称: linear | step | plateau | cosine\n",
    "    \"\"\"\n",
    "    if lr_policy == 'linear':\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "    elif lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=18, gamma=0.1)\n",
    "    elif lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0)\n",
    "    else:\n",
    "        print('learning rate policy [%s] is not implemented'%(lr_policy))\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义回归模型与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_model = Change()\n",
    "change_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/epoch257_batchsize1_params.pkl'))\n",
    "initial_lr = 0.01\n",
    "optimizer = optim.Adam(change_model.parameters(), lr = initial_lr)\n",
    "scheduler = get_scheduler(optimizer, 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train begin......\n",
      "[epoch: 0 ]   loss= tensor(139.096054077148438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 1 ]   loss= tensor(138.156982421875000, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 2 ]   loss= tensor(139.832992553710938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 3 ]   loss= tensor(140.205551147460938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 4 ]   loss= tensor(139.198715209960938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 4 ]   loss= tensor(136.126831054687500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 5 ]   loss= tensor(138.494491577148438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 6 ]   loss= tensor(139.784576416015625, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 7 ]   loss= tensor(140.725891113281250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 8 ]   loss= tensor(140.100570678710938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 9 ]   loss= tensor(139.572280883789062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 9 ]   loss= tensor(136.241729736328125, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 10 ]   loss= tensor(139.280899047851562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 11 ]   loss= tensor(139.483139038085938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 12 ]   loss= tensor(139.533615112304688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 13 ]   loss= tensor(138.888717651367188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 14 ]   loss= tensor(139.064682006835938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 14 ]   loss= tensor(137.186584472656250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 15 ]   loss= tensor(140.020278930664062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 16 ]   loss= tensor(138.590072631835938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 17 ]   loss= tensor(139.413986206054688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 18 ]   loss= tensor(139.100204467773438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 19 ]   loss= tensor(138.790893554687500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 19 ]   loss= tensor(139.095626831054688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 20 ]   loss= tensor(139.344253540039062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 21 ]   loss= tensor(139.495407104492188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 22 ]   loss= tensor(137.799911499023438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 23 ]   loss= tensor(138.156906127929688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 24 ]   loss= tensor(138.814819335937500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 24 ]   loss= tensor(137.246261596679688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 25 ]   loss= tensor(138.331756591796875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 26 ]   loss= tensor(138.586730957031250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 27 ]   loss= tensor(139.197891235351562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 28 ]   loss= tensor(138.244186401367188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 29 ]   loss= tensor(139.575302124023438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 29 ]   loss= tensor(135.707839965820312, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 30 ]   loss= tensor(138.474716186523438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 31 ]   loss= tensor(137.990447998046875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 32 ]   loss= tensor(137.266098022460938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 33 ]   loss= tensor(138.265991210937500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 34 ]   loss= tensor(138.788757324218750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 34 ]   loss= tensor(135.707656860351562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 35 ]   loss= tensor(139.602020263671875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 36 ]   loss= tensor(138.278579711914062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 37 ]   loss= tensor(137.626800537109375, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 38 ]   loss= tensor(138.983627319335938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 39 ]   loss= tensor(138.322082519531250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 39 ]   loss= tensor(136.693969726562500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 40 ]   loss= tensor(138.864364624023438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 41 ]   loss= tensor(138.010528564453125, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 42 ]   loss= tensor(139.044082641601562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 43 ]   loss= tensor(138.386398315429688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 44 ]   loss= tensor(137.324798583984375, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 44 ]   loss= tensor(138.712707519531250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 45 ]   loss= tensor(138.472717285156250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 46 ]   loss= tensor(137.599731445312500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 47 ]   loss= tensor(138.334869384765625, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 48 ]   loss= tensor(138.724822998046875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 49 ]   loss= tensor(138.789001464843750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 49 ]   loss= tensor(137.865173339843750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 50 ]   loss= tensor(140.305648803710938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 51 ]   loss= tensor(137.529739379882812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 52 ]   loss= tensor(137.522262573242188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 53 ]   loss= tensor(138.084594726562500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 54 ]   loss= tensor(137.507431030273438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 54 ]   loss= tensor(136.343032836914062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 55 ]   loss= tensor(138.070785522460938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 56 ]   loss= tensor(138.063125610351562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 57 ]   loss= tensor(138.999374389648438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 58 ]   loss= tensor(139.081436157226562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 59 ]   loss= tensor(137.683029174804688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 59 ]   loss= tensor(136.677886962890625, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 60 ]   loss= tensor(138.275772094726562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 61 ]   loss= tensor(139.112472534179688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 62 ]   loss= tensor(137.346191406250000, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 63 ]   loss= tensor(138.017044067382812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 64 ]   loss= tensor(138.841796875000000, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 64 ]   loss= tensor(135.698059082031250, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 65 ]   loss= tensor(137.423629760742188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 66 ]   loss= tensor(137.911087036132812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 67 ]   loss= tensor(138.890182495117188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 68 ]   loss= tensor(138.384475708007812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 69 ]   loss= tensor(137.944259643554688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 69 ]   loss= tensor(134.478485107421875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 70 ]   loss= tensor(137.408966064453125, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 71 ]   loss= tensor(138.340499877929688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 72 ]   loss= tensor(137.685440063476562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 73 ]   loss= tensor(136.414642333984375, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 74 ]   loss= tensor(138.128845214843750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 74 ]   loss= tensor(136.370635986328125, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 75 ]   loss= tensor(138.967849731445312, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 76 ]   loss= tensor(137.912216186523438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 77 ]   loss= tensor(139.068557739257812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 78 ]   loss= tensor(137.895767211914062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 79 ]   loss= tensor(137.839523315429688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 79 ]   loss= tensor(135.026260375976562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 80 ]   loss= tensor(137.138595581054688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 81 ]   loss= tensor(137.184463500976562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 82 ]   loss= tensor(137.874801635742188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 83 ]   loss= tensor(137.928695678710938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 84 ]   loss= tensor(136.373657226562500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 84 ]   loss= tensor(134.771194458007812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 85 ]   loss= tensor(138.410324096679688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 86 ]   loss= tensor(137.827438354492188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 87 ]   loss= tensor(138.502792358398438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 88 ]   loss= tensor(137.438247680664062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 89 ]   loss= tensor(137.937820434570312, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 89 ]   loss= tensor(134.209472656250000, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 90 ]   loss= tensor(137.765396118164062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 91 ]   loss= tensor(137.572631835937500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 92 ]   loss= tensor(137.523208618164062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 93 ]   loss= tensor(138.944808959960938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 94 ]   loss= tensor(137.651229858398438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 94 ]   loss= tensor(132.736755371093750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "model save!\n",
      "[epoch: 95 ]   loss= tensor(137.876968383789062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 96 ]   loss= tensor(137.219451904296875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 97 ]   loss= tensor(137.542007446289062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 98 ]   loss= tensor(137.999206542968750, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 99 ]   loss= tensor(137.648849487304688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 99 ]   loss= tensor(132.961380004882812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 100 ]   loss= tensor(137.571533203125000, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 101 ]   loss= tensor(136.675460815429688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 102 ]   loss= tensor(136.695770263671875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 103 ]   loss= tensor(137.264633178710938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 104 ]   loss= tensor(136.959869384765625, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 104 ]   loss= tensor(136.960891723632812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 105 ]   loss= tensor(136.959686279296875, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 106 ]   loss= tensor(138.585327148437500, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 107 ]   loss= tensor(137.493576049804688, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 108 ]   loss= tensor(138.296401977539062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 109 ]   loss= tensor(137.080764770507812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 109 ]   loss= tensor(134.858596801757812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 110 ]   loss= tensor(137.051101684570312, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 111 ]   loss= tensor(137.387405395507812, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 112 ]   loss= tensor(137.360855102539062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 113 ]   loss= tensor(136.855728149414062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 114 ]   loss= tensor(137.068344116210938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 114 ]   loss= tensor(135.761138916015625, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 115 ]   loss= tensor(136.783248901367188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 116 ]   loss= tensor(136.698623657226562, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 117 ]   loss= tensor(137.291122436523438, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 118 ]   loss= tensor(137.454666137695312, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 119 ]   loss= tensor(136.272506713867188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "进行验证.......\n",
      "[epoch: 119 ]   loss= tensor(135.757064819335938, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 120 ]   loss= tensor(137.898941040039062, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 121 ]   loss= tensor(137.007522583007812, grad_fn=<DivBackward0>) lr = 0.010000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e46545b320a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-30c791c23f34>\u001b[0m in \u001b[0;36mtrain_2\u001b[1;34m(optimizer, change_model, scheduler)\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[0mtrain_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mloss_reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                     \u001b[0mloss_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_2(optimizer, change_model, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_2_list, val_loss_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTM_CNN()\n",
    "Loss = nn.MSELoss()\n",
    "model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_params.pkl'))\n",
    "x1 = Variable(torch.LongTensor(x_batch_train[:10]))\n",
    "x2 = Variable(torch.FloatTensor(x_csv_train[:10]))\n",
    "x3 = Variable(torch.FloatTensor(target_list_train[:10]))\n",
    "print(\"target.shape: \"+str(x3.shape))\n",
    "print(x3)\n",
    "y = Variable(torch.FloatTensor(y_csv_train[:10]))\n",
    "pred = model(x1, x2)\n",
    "change_model = Change()\n",
    "pred2 = change_model(pred)\n",
    "print(\"pred2.shape: \"+str(pred2.shape))\n",
    "print(pred2)\n",
    "loss = Loss(pred2, x3)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算R@1在tIOU为0.1/0.3/0.5/0.7的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_IoU(i0,i1):\n",
    "    union = (min(i0[0], i1[0]), max(i0[1], i1[1]))\n",
    "    inter = (max(i0[0], i1[0]), min(i0[1], i1[1]))\n",
    "    iou = 1.0*(inter[1]-inter[0])/(union[1]-union[0])\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "compute recall at certain IoU\n",
    "'''\n",
    "def compute_IoU_recall_top_n_forreg(top_n, iou_thresh, sentence_image_mat, sentence_image_reg_mat, sclips, iclips):\n",
    "    correct_num = 0.0\n",
    "    for k in range(sentence_image_mat.shape[0]):\n",
    "        gt = sclips[k]\n",
    "        gt_start = float(gt.split(\"_\")[1])\n",
    "        gt_end = float(gt.split(\"_\")[2])\n",
    "        sim_v = [v for v in sentence_image_mat[k]]\n",
    "        starts = [s for s in sentence_image_reg_mat[k,:,0]]\n",
    "        ends = [e for e in sentence_image_reg_mat[k,:,1]]\n",
    "        picks = nms_temporal(starts,ends, sim_v, iou_thresh-0.05)\n",
    "        #sim_argsort=np.argsort(sim_v)[::-1][0:top_n]\n",
    "        if top_n<len(picks): picks=picks[0:top_n]\n",
    "        for index in picks:\n",
    "            pred_start = sentence_image_reg_mat[k, index, 0]\n",
    "            pred_end = sentence_image_reg_mat[k, index, 1]\n",
    "            iou = calculate_IoU((gt_start, gt_end),(pred_start, pred_end))\n",
    "            if iou>=iou_thresh:\n",
    "                correct_num+=1\n",
    "                break\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAL_测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = []\n",
    "resualt_text_path='C:/Users/wuxun/Desktop/resulat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_3():\n",
    "    change_model = Change()\n",
    "    model = LSTM_CNN()\n",
    "    model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/60poch_20200713_params.pkl'))\n",
    "    optimizer = optim.Adam(change_model.parameters(), lr = 0.001)\n",
    "    best_val_loss_2 = 1000000\n",
    "    print(\"train begin......\")\n",
    "    with open(resualt_text_path,'a') as f:\n",
    " \n",
    "        for epoch in range(200):\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size)\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            val_loss_avg = 0 \n",
    "            val_alignmentloss_sum =0\n",
    "            val_regloss_sum =0\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                if x_csv.shape[0]==batch_size:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                    target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                    pred = model(x1, x2)\n",
    "                    pred2, loss_alignment = change_model(pred)\n",
    "\n",
    "                    loss_reg = torch.abs(pred2 - target_time).mean()\n",
    "                    for i in range(pred2.shape[0]):\n",
    "                        f.write('target_time:[%d, %d]      (l_reg, r_reg):[%.3f, %.3f]\\n' %(target_time[i][0],target_time[i][1],pred2[i][0], pred2[i][1]))\n",
    "                        #print('target_time:[%d, %d]  (l_reg, r_reg):[%.3f, %.3f]' %(target_time[i][0],target_time[i][1],pred2[i][0], pred2[i][1]))\n",
    "                    val_regloss_sum +=loss_reg\n",
    "                    loss_reg = loss_reg*lamba + loss_alignment\n",
    "\n",
    "                    val_loss_sum +=loss_reg\n",
    "                    val_alignmentloss_sum += loss_alignment\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    nn.utils.clip_grad_norm_(change_model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                    optimizer.step()\n",
    "\n",
    "            val_loss_avg = val_loss_sum / count\n",
    "            f.write(\"======================================================================================\\n\")\n",
    "            #print(\"============================================================================\")\n",
    "            #print(\"epoch\"+str(epoch)+\": sum_loss:\"+str((val_loss_avg))+\"  loss_alignment: \"+str(val_alignmentloss_sum/count)+\"  loss_reg: \"+str(val_regloss_sum/count))\n",
    "            f.write('[epoch:%d]     sum_loss: %.3f     loss_alignment: %.3f    loss_reg: %.3f\\n' %(epoch, val_loss_avg, val_alignmentloss_sum/count, val_regloss_sum/count))\n",
    "            print('[epoch:%d]   sum_loss: %.3f   loss_alignment: %.3f  loss_reg: %.3f' %(epoch, val_loss_avg, val_alignmentloss_sum/count, val_regloss_sum/count))\n",
    "            val.append(val_loss_avg)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
