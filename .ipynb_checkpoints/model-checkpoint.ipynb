{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入相应的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime  # 用于计算时间\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#import tensorflow.contrib.keras as kr\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from torchtext import data\n",
    "import jieba\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=15)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_path = 'C:/Users/wuxun/Desktop/Data/feat_dat/'\n",
    "image_path = 'C:/Users/wuxun/Desktop/Data/image/'#存储到image文件夹中\n",
    "clip_path = 'C:/Users/wuxun/Desktop/Data/clip/'\n",
    "text_dir = 'C:/Users/wuxun/Desktop/Data/clear_text.txt'\n",
    "vocab_dir = 'C:/Users/wuxun/Desktop/Data/vocab.txt'\n",
    "train_path = 'C:/Users/wuxun/Desktop/Data/training/training.txt'\n",
    "val_path = 'C:/Users/wuxun/Desktop/Data/validation/validation.txt'\n",
    "csv_path = 'D:/csv/'\n",
    "save_path = 'C:/Users/wuxun/Desktop/Data/save_model/'\n",
    "save_path2 = 'C:/Users/wuxun/Desktop/Data/save_model2/params.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#固定随机数种子\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def read_file(filename):\n",
    "\n",
    "    \"\"\"读取文件数据\"\"\"\n",
    "    \n",
    "    contents = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            contents.append(re.split('[, \\n.]',line))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(text_dir, vocab_dir, vocab_size=3000):\n",
    "\n",
    "    \"\"\"根据训练集构建词汇表，存储\"\"\"\n",
    "    data_train = read_file(text_dir)\n",
    "    all_data = []\n",
    "    for content in data_train:\n",
    "        for k in content:\n",
    "            if len(k)!=0:\n",
    "                all_data.append(k)\n",
    "    print(all_data)\n",
    "    counter = Counter(all_data)\n",
    "    count_pairs = counter.most_common(vocab_size - 1)\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    # 添加一个 <PAD> 来将所有文本pad为同一长度\n",
    "    words = ['<PAD>'] + list(words)\n",
    "    open(vocab_dir, mode='w').write('\\n'.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(vocab_dir):\n",
    "\n",
    "    \"\"\"读取词汇表\"\"\"\n",
    "\n",
    "    with open(vocab_dir) as fp:\n",
    "        words = [(_.strip()) for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_words(content, words):\n",
    "\n",
    "    \"\"\"将id表示的内容转换为文字\"\"\"\n",
    "\n",
    "    return ''.join(words[x] for x in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(path, csv_path):\n",
    "    '''\n",
    "    获得最终的数据集\n",
    "    path:文本数据集\n",
    "    csv_path\n",
    "    '''\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    source_csv=[]\n",
    "    target_csv=[]\n",
    "    fake_time_list=[]\n",
    "    source_time_list=[]\n",
    "    target_time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            source = List[4]\n",
    "            target = List[5]\n",
    "            fake_time = (List[7].split('_'))\n",
    "            fake_time_l=int(fake_time[0])\n",
    "            fake_time_r=int(fake_time[1])\n",
    "            fake_time_list.append([fake_time_l, fake_time_r])\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点\n",
    "            source = source.split('_')\n",
    "            target = target.split('_')\n",
    "            \n",
    "            source_time = (float(source[0])+float(source[1]))//2\n",
    "            source_time_list.append([float(source[0]),float(source[1])])\n",
    "            source_frame_num = int(source_time/time_length*500)\n",
    "            source_frame = frame_sum.loc[source_frame_num]\n",
    "            source_csv.append([source_frame])\n",
    "            \n",
    "            target_time = (float(target[0])+float(target[1]))//2\n",
    "            target_time_list.append([float(target[0]),float(target[1])])\n",
    "            target_frame_num = int(target_time/time_length*500)\n",
    "            target_frame = frame_sum.loc[target_frame_num]\n",
    "            target_csv.append([target_frame])\n",
    "            \n",
    "            #添加其余帧数据作为对抗样本\n",
    "            fake_time = (fake_time_l + fake_time_r)//2\n",
    "            fake_time_num = int(fake_time/time_length*500)\n",
    "            #print(str(count)+\"     \"+str(fake_time_num))\n",
    "            fake_frame = frame_sum.loc[fake_time_num]\n",
    "            \n",
    "            #补充数据\n",
    "            source_csv.append([source_frame])\n",
    "            data_id.append(sentence_id)\n",
    "            target_csv.append([fake_frame])\n",
    "            source_time_list.append([float(source[0]),float(source[1])])\n",
    "            target_time_list.append([fake_time_l, fake_time_r])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)\n",
    "            \n",
    "    print(len(batch_seq),len(source_csv),len(target_csv))\n",
    "    \n",
    "    return batch_seq, source_csv, target_csv, source_time_list, target_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096 3096 3096\n"
     ]
    }
   ],
   "source": [
    "#训练集\n",
    "x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train = get_dict(train_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046 1046 1046\n"
     ]
    }
   ],
   "source": [
    "#验证集\n",
    "x_batch_val, x_csv_val, y_csv_val, source_list_val, target_list_val = get_dict(val_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lamba = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        #self.rnn = nn.GRU(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "        self.f1 = nn.Sequential(nn.Linear(256,128),\n",
    "                                nn.Dropout(0.8),\n",
    "                                nn.ReLU())\n",
    "\n",
    "        self.f2 = nn.Sequential(nn.Linear(128,64))\n",
    "        \n",
    "        \n",
    "        self.conv1=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1,10,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "        \n",
    "        self.conv2=torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(10,20,3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "\n",
    "        #self.fc1=torch.nn.Linear(2520,128)\n",
    "        self.fc1=torch.nn.Linear(512,128)\n",
    "        self.fc1_drop=torch.nn.Dropout(p=0.4)\n",
    "        self.fc2=torch.nn.Linear(128, 64)\n",
    "        \n",
    "        #特征融合\n",
    "        self.final_fc = nn.Linear(in_features=128, out_features=64)\n",
    "        self.score_fc = torch.nn.Conv2d(64,3,kernel_size=1,stride=1)\n",
    "        \n",
    "        \n",
    "    def cnnout(self, x2):\n",
    "        in_fc=x2.view(x2.size(0),-1)\n",
    "        out_fc1=self.fc1(in_fc)\n",
    "        out_drop=self.fc1_drop(out_fc1)\n",
    "        out_fc2=self.fc2(out_drop)\n",
    "        return out_fc2\n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        if x1.shape[0]!=2:\n",
    "            #lstm\n",
    "            x = self.embedding(x1)\n",
    "            x,_ = self.rnn(x)\n",
    "            x = F.dropout(x,p=0.8)\n",
    "            x = self.f1(x[:,-1,:])\n",
    "            lstm_output = self.f2(x)\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            #concat\n",
    "            output = torch.cat((lstm_output, cnn_out), 1)\n",
    "            output = self.final_fc(output)\n",
    "            return output\n",
    "        else:\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            return cnn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成批次数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(x_batch, x_csv, y_csv, source_list, target_list, batch_size=32):\n",
    "\n",
    "    \"\"\"\n",
    "    生成批次数据\n",
    "    \"\"\"\n",
    "\n",
    "    data_len = x_batch.shape[0]\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_batch_shuffle = x_batch[indices]\n",
    "    x_csv_shuffle =np.array(x_csv)[indices]\n",
    "    y_csv_shuffle = np.array(y_csv)[indices]\n",
    "    source_list = np.array(source_list)[indices]\n",
    "    target_list = np.array(target_list)[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_batch_shuffle[start_id:end_id], x_csv_shuffle[start_id:end_id], y_csv_shuffle[start_id:end_id], source_list[start_id:end_id], target_list[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储loss数据\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = LSTM_CNN()\n",
    "    #model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/110epoch_20200713_params.pkl'))\n",
    "    Loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    T=Variable(torch.FloatTensor([[1.0,1.0],[1.0,1.0]]))\n",
    "    best_val_loss = 1000000\n",
    "    print(\"train begin......\")\n",
    "\n",
    "    for epoch in range(100):\n",
    "        batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, batch_size)\n",
    "        print(\"====================  epoch:\"+str(epoch)+\"  ========================\")\n",
    "        train_loss_sum = 0\n",
    "        train_loss_avg = 0\n",
    "        count = 0\n",
    "        for x_batch, x_csv, y_csv, source_time, target_time in batch_train:\n",
    "            if x_csv.shape[0]==batch_size:\n",
    "                count += 1\n",
    "                x1 = Variable(torch.LongTensor(x_batch))\n",
    "                x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                pred_y = model(x1, x2)\n",
    "                negtive = model(T, x2)\n",
    "                postive = model(T, y)\n",
    "                loss_reg = Loss(pred_y, postive, negtive)\n",
    "                train_loss_sum += loss_reg\n",
    "                optimizer.zero_grad()\n",
    "                loss_reg.backward()\n",
    "                #nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                optimizer.step()\n",
    "                \n",
    "        train_loss_avg = train_loss_sum /count\n",
    "        print(\"train_loss: \"+str(train_loss_sum))\n",
    "        train_loss_list.append(train_loss_sum)\n",
    "\n",
    "        #对模型进行验证：\n",
    "        if (epoch+1)%5 == 0:\n",
    "            print(\"进行验证.....\")\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            val_loss_avg = 0\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size)\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                if x_csv.shape[0]==batch_size:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                    pred_y = model(x1, x2)\n",
    "                    negtive = model(T, x2)\n",
    "                    postive = model(T, y)\n",
    "                    loss_reg = Loss(pred_y, postive, negtive)\n",
    "                    #loss_reg = torch.abs(pred_y - postive).mean()\n",
    "                    val_loss_sum += loss_reg\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    #nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            val_loss_avg = val_loss_sum /count\n",
    "            print(\"val_loss: \"+str(val_loss_sum))\n",
    "            val_loss_list.append(val_loss_sum)   \n",
    "            torch.save(model.state_dict(), save_path+str(epoch)+'_not_better_params.pkl')\n",
    "            if val_loss_sum < best_val_loss:\n",
    "                torch.save(model.state_dict(), save_path+str(epoch)+'_better_params.pkl')\n",
    "                best_val_loss = val_loss_sum\n",
    "                print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 绘制Loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(train_loss_list, val_loss_list):\n",
    "    x1 = range(0, len(train_loss_list))\n",
    "    x2 = range(0, len(val_loss_list))\n",
    "    #with plt.style.context(['science']):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, train_loss_list[:len(train_loss_list)], 'o-')\n",
    "    plt.title('train loss vs. epoches')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2,val_loss_list[:len(val_loss_list)] , '.-')\n",
    "    plt.xlabel('Val loss vs. epoches')\n",
    "    plt.ylabel('Val loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+4HWV57vHvTRKC/AoJCcivkCBg\nC/YYZIvlFBWqIFI0WFCiiAhSStVTq1ULBStETytw2arVHpoqCAgEC0Wj2Kb8EGhrhexooAaMhEAk\ngBoIAhFBAvf5Y94tK9u1917JnrXWXsn9ua659qyZd2aeZwf2s2bemXdkm4iIiNHaotsBRETEpiEF\nJSIiapGCEhERtUhBiYiIWqSgRERELVJQIiKiFikoscmQdKGkj23ktjdLOrXumDZlkr4s6ZPdjiPG\njvHdDiACQNL9wKm2b9jYfdg+vb6IImJD5QwleoKkfPmJGONSUKLrJF0GTAe+IWmtpI9KmiHJkt4j\n6cfATaXtP0v6iaTHJd0qaf+G/fz6EoykQyWtkvTnkn4m6WFJJ7cYzxaSzpa0smx7qaRJZd1Wkr4i\n6VFJP5e0SNLOZd27Ja2Q9KSk+ySd0GTfu0r6paQpDcsOkPSIpAmS9pZ0S8nvEUlXbcDv8RRJd0t6\nTNJCSXs2rLOkPy3xPSLpAklbjJRvWX+IpO+UfB+Q9O6Gw06WdF3J+TZJL2nY7rckXS9pjaRlkt7W\nsO4oSXeV7R6U9OFW84wxzHamTF2fgPuB1zd8ngEYuBTYBnhRWX4KsB0wEfgMsKRhmy8DnyzzhwLr\ngLnABOAo4Clg8hDHv5nqktvAMZYDewHbAv8CXFbW/THwDWBrYBxwILB9ifEJ4KWl3S7A/kMc6ybg\njxo+XwBcWOavBM6i+rK3FXBIi7+/Y0rMv011Kfts4DsN6w18G5hCVbx/1GK+04EngbeX3+OOwKyG\n3/ca4KByzMuB+WXdNsADwMll3SuARwZ+J8DDwKvL/GTgFd3+bzDT6KecocRYd47tX9j+JYDti2w/\nafsZ4Bzg5Y3fpgd5Fphr+1nb3wLWAi9t4ZgnAH9re4XttcCZwJxy2e1Zqj+qe9t+zvZi20+U7Z4H\nXibpRbYftr10iP1fQfUHGkkC5pRlAzHvCexq+2nb/9lCvFAVur+xfbftdcBfA7Maz1KA82yvsf1j\nqmL89hbyPQG4wfaV5ff4qO0lDfv8F9u3l2NeDswqy48G7rd9se11tr8HXAMc15DnfpK2t/1YWR89\nLgUlxroHBmYkjZP0KUn3SnqC6qwGYOoQ2z5a/tANeIrqG/hIdgVWNnxeSfUte2fgMmAhMF/SQ5LO\nlzTB9i+A44HTgYfLZaDfGmL/VwMHS9oVeA3V2cN/lHUfBQTcLmmppFNaiBeqIvTZclnq51RnDgJ2\na2jzQMP8ypLnSPnuAdw7zHF/0jDf+PvdE3jVQDwlphOAF5f1x1KdNa4sl/gObi3NGMtSUGKsGGrY\n68bl7wBmA68HJlFdFoPqD2edHqL6gzhgOtXls5+Wb+nn2t4P+N9U38TfBWB7oe3DqS53/RD4p2Y7\nt/1z4N+Bt5WcrrTLdSn7J7b/yPauVGcd/yBp7xZifgD4Y9s7NEwvsv2dhjZ7DMrpoZHyLft9CRvu\nAeCWQfFsa/tPSp6LbM8GdgK+Bnx1I44RY0wKSowVP6W6hj+c7YBngEep+jD+uk2xXAl8UNJMSduW\n41xle52kwyT9jqRxVH0mzwLPSdpZ0pslbVNiXAs8N8wxrqAqRMfywuUuJL1V0u7l42NUBXW4/Qy4\nEDhz4CYFSZMkvXVQm49ImixpD+ADwECH/5D5Ul3Ger2kt0kaL2lHSbMY2TeBfSWdWG42mCDplZJ+\nW9KWkk6QNMn2s1S/x1ZyjDEuBSXGir8Bzi6XR4a64+dSqssxDwJ3Ad9tUywXUV3auhW4D3ga+D9l\n3YupLlk9AdwN3AJ8her/pT+n+ra/Bngt8N5hjrEA2IfqrOeOhuWvBG6TtLa0+YDt+wDKJbDfuHMM\nwPa1wHlUl+KeAH4AvHFQs68Di4ElwHXAl0bKt/S3HFVyW1O2ffkweQ3E8yRwBFX/0ENUl8bOo7qZ\nAuBE4P4S6+nAO0faZ4x9KmfaEbEJk2RgH9vLux1LbLpyhhIREbVIQYmIiFrkkldERNQiZygREVGL\nzWrAvalTp3rGjBndDiMioqcsXrz4EdvTRmq3WRWUGTNm0N/f3+0wIiJ6iqSVI7fq8iUvSUeWUUiX\nSzqjyfqJkq4q62+TNKMsn6FqxNYlZbqw07FHRMT6unaGUp40/gJwOLAKWCRpge27Gpq9B3jM9t6S\n5lA9GHV8WXev7Vae2I2IiA7o5hnKQcDyMsLpr4D5VOM0NZoNXFLmrwZeV0ZnjYiIMaabBWU31h/9\ndBXrj4y6XpsyrtDjVEOHA8yU9P0yUumrhzqIpNMk9UvqX716dX3RR0TEerpZUJqdaQx+KGaoNg8D\n020fAHwIuELS9s0OYnue7T7bfdOmjXiTQkREbKRuFpRVrD+c9u68MJz2b7QpL/uZBKyx/YztRwFs\nL6Z6X8O+bY84IiKG1M2CsgjYpwyZvSXVqKQLBrVZAJxU5o8DbrJtSdNKpz6S9qIatXVFh+KOiIgm\nunaXV3m3xPup3n43DrjI9lJJc4F+2wuohte+TNJyqqGz55TNXwPMlbSO6j0Kp9te0/ksIiJiwGY1\nlldfX5/zYGNExIaRtNh230jtMpZXRETUIgUlIiJqkYISERG1SEGJiIhapKBEREQtUlAiIqIWKSgR\nEVGLFJSIiKhFCkpERNQiBSUiImqRghIREbVIQYmIiFqkoERERC1SUCIiohYpKBERUYsUlIiIqEUK\nSkRE1CIFJSIiajFiQZG0jaQtyvy+kt4saUL7Q4uIiF7SyhnKrcBWknYDbgROBr7czqAiIqL3tFJQ\nZPsp4A+Bv7f9FmC/9oYVERG9pqWCIulg4ATgurJsfPtCioiIXtRKQfkz4EzgWttLJe0FfLu9YUVE\nRK8Z8UzD9i3ALQClc/4R23/a7sAiIqK3tHKX1xWStpe0DXAXsEzSR9ofWkRE9JJWLnntZ/sJ4Bjg\nW8B04MS2RhURET2nlYIyoTx3cgzwddvPAm5vWBER0WtaKSj/CNwPbAPcKmlP4Il2BhUREb2nlU75\nzwGfa1i0UtJh7QspIiJ6USud8pMk/a2k/jJ9mupsJSIi4tdaueR1EfAk8LYyPQFc3M6gIiKi97Ty\nxPtLbB/b8PlcSUvaFVBERPSmVs5QfinpkIEPkn4P+GX7QoqIiF7UyhnKnwCXSJoECFgDvLudQUVE\nRO9p5S6vJcDLJW1fPueW4YiI+A1DFhRJHxpiOQC2/7ZNMUVERA8arg9luxGmUZN0pKRlkpZLOqPJ\n+omSrirrb5M0o2HdmWX5MklvqCOeiIjYeEOeodg+t50HljQO+AJwOLAKWCRpge27Gpq9B3jM9t6S\n5gDnAcdL2g+YA+wP7ArcIGlf28+1M+aIiBhaK3d5tctBwHLbK2z/CpgPzB7UZjZwSZm/Gnidqmtu\ns4H5tp+xfR+wvOwvIiK6pJsFZTfggYbPq8qypm1srwMeB3ZscVsAJJ028JT/6tWrawo9IiIG62ZB\nUZNlg0cxHqpNK9tWC+15tvts902bNm0DQ4yIiFaNeNuwpInAscCMxva2547y2KuAPRo+7w48NESb\nVZLGA5OonoNpZduIiOigVs5Qvk7VZ7EO+EXDNFqLgH0kzZS0JVUn+4JBbRYAJ5X544CbbLssn1Pu\nApsJ7APcXkNMERGxkVp5Un5320fWfWDb6yS9H1gIjAMusr1U0lyg3/YC4EvAZZKWU52ZzCnbLpX0\nVapXEq8D3pc7vCIiukvVF/5hGkjzgL+3/T+dCal9+vr63N/f3+0wIiJ6iqTFtvtGatfKGcohwLsl\n3Qc8Q9Uhbtv/a5QxRkTEJqSVgvLGtkcRERE9b7ixvLYvA0E+2cF4IiKiRw13hnIFcDSwmN989sPA\nXm2MKyIiesxwY3kdXX7O7Fw4ERHRq1rpQ0HSZKpnPbYaWGb71nYFFRERvaeVJ+VPBT5A9TT6EuB3\ngf8Gfr+9oUVERC9p5Un5DwCvBFbaPgw4AMgoixERsZ5WCsrTtp+Galwv2z8EXtresCIiote00oey\nStIOwNeA6yU9RgZijIiIQUYsKLbfUmbPkfRtqhF//62tUUVERM8ZtqBI2gK40/bLAGzf0pGoIiKi\n5wzbh2L7eeAOSdM7FE9ERPSoVvpQdgGWSrqdhveg2H5z26KKiIie00pBObftUURERM9rpaAcZfsv\nGhdIOg9If0pERPxaK8+hHN5kWYa0j4iI9Qw3fP2fAO8F9pJ0Z8Oq7YD/andgERHRW0Yavv5fgb8B\nzmhY/qTtNW2NKiIies5ww9c/DjwOvL1z4URERK9qpQ8lIiJiRCkoERFRixSUiIioRQpKRETUIgUl\nIiJqkYISERG1SEGJiIhapKBEREQtUlAiIqIWKSgREVGLFJSIiKhFCkpERNQiBSUiImqRghIREbVI\nQYmIiFqkoERERC26UlAkTZF0vaR7ys/JQ7Q7qbS5R9JJDctvlrRM0pIy7dS56CMioplunaGcAdxo\nex/gRtZ/xTBQFR3g48CrgIOAjw8qPCfYnlWmn3Ui6IiIGFq3Csps4JIyfwlwTJM2bwCut73G9mPA\n9cCRHYovIiI2ULcKys62HwYoP5tdstoNeKDh86qybMDF5XLXxyRpqANJOk1Sv6T+1atX1xF7REQ0\nMb5dO5Z0A/DiJqvOanUXTZa5/DzB9oOStgOuAU4ELm22E9vzgHkAfX19btYmIiJGr20Fxfbrh1on\n6aeSdrH9sKRdgGZ9IKuAQxs+7w7cXPb9YPn5pKQrqPpYmhaUiIjojG5d8loADNy1dRLw9SZtFgJH\nSJpcOuOPABZKGi9pKoCkCcDRwA86EHNERAxDduevAknaEfgqMB34MfBW22sk9QGn2z61tDsF+Muy\n2f+1fbGkbYBbgQnAOOAG4EO2n2vhuKuBlbUn1F5TgUe6HUSHJefNQ3LuHXvanjZSo64UlGidpH7b\nfd2Oo5OS8+YhOW968qR8RETUIgUlIiJqkYIy9s3rdgBdkJw3D8l5E5M+lIiIqEXOUCIiohYpKBER\nUYsUlDFgtMP5N6xfIKknHvIcTc6StpZ0naQfSloq6VOdjX7DSDqyvG5huaRmI2tPlHRVWX+bpBkN\n684sy5dJekMn4x6Njc1Z0uGSFkv6n/Lz9zsd+8YYzb9xWT9d0lpJH+5UzG1hO1OXJ+B84IwyfwZw\nXpM2U4AV5efkMj+5Yf0fAlcAP+h2Pu3OGdgaOKy02RL4D+CN3c5piDzHAfcCe5VY7wD2G9TmvcCF\nZX4OcFWZ36+0nwjMLPsZ1+2c2pzzAcCuZf5lwIPdzqed+Tasvwb4Z+DD3c5nNFPOUMaGUQ3nL2lb\n4EPAJzsQa102OmfbT9n+NoDtXwHfoxrrbSw6CFhue0WJdT5V7o0afxdXA68rI2jPBubbfsb2fcDy\nsr+xbqNztv192w+V5UuBrSRN7EjUG280/8ZIOobqy9LSDsXbNikoY8Noh/P/BPBp4Kl2BlmzOl5h\ngKQdgDdRvahtLBoxh8Y2ttcBjwM7trjtWDSanBsdC3zf9jNtirMuG51vGUrqL4BzOxBn27VttOFY\nX7uG85c0C9jb9gcHX5fttja/wgBJ44Ergc/ZXrHhEXbEsDmM0KaVbcei0eRcrZT2B86jGhR2rBtN\nvucCf2d77TCvdeoZKSgd4vYN538wcKCk+6n+PXeSdLPtQ+myNuY8YB5wj+3P1BBuu6wC9mj4vDvw\n0BBtVpUiOQlY0+K2Y9FockbS7sC1wLts39v+cEdtNPm+CjhO0vnADsDzkp62/fn2h90G3e7EyWSA\nC1i/g/r8Jm2mAPdRdUpPLvNTBrWZQe90yo8qZ6r+omuALbqdywh5jqe6Pj6TFzps9x/U5n2s32H7\n1TK/P+t3yq+gNzrlR5PzDqX9sd3OoxP5DmpzDj3eKd/1ADIZqmvHNwL3lJ8DfzT7gC82tDuFqmN2\nOXByk/30UkHZ6JypvgEauBtYUqZTu53TMLkeBfyI6k6gs8qyucCby/xWVHf4LAduB/Zq2Passt0y\nxuidbHXmDJwN/KLh33UJsFO382nnv3HDPnq+oGTolYiIqEXu8oqIiFqkoERERC1SUCIiohab1W3D\nU6dO9YwZM7odRkRET1m8ePEjbuGd8l0tKJKOBD5LNRbOF21/atD6icClwIHAo8Dxtu8vD/DdTXXn\nC8B3bZ8+0vFmzJhBf39/fQlERGwGJK1spV3XCoqkccAXgMOpHvpZJGmB7bsamr0HeMz23pLmUD05\ne3xZd6/tWR0NOiIihtTNPpRRDagWERFjSzcLymgHkJsp6fuSbpH06qEOIuk0Sf2S+levXl1f9BER\nsZ5uFpTRDKj2MDDd9gFUw7ZfIWn7ZgexPc92n+2+adNG7FOKiIiN1M2CsiEDqtE4oJqr90M8CmB7\nMdVwB/u2PeKIiBhSNwvKImAfSTMlbUk1YNqCQW0WAAOvuj0OuMm2JU0rnfpI2gvYh2pwtoiI6JKu\n3eVle52k9wMLqW4bvsj2UklzgX7bC4AvAZdJWk411POcsvlrgLmS1gHPAafbXtP5LCIiYsBmNThk\nX1+f8xxKRMSGkbTYdt9I7TL0SkRE1CIFJSIiapGCEhERtUhBiYiIWqSgRERELVJQIiKiFikoERFR\nixSUiIioRQpKRETUIgUlIiJqkYISERG1SEGJiIhapKBEREQtUlAiIqIWKSgREVGLFJSIiKhFCkpE\nRNQiBSUiImqRghIREbVIQYmIiFqkoERERC1SUCIiohYjFhRJH5C0vSpfkvQ9SUd0IriIiOgdrZyh\nnGL7CeAIYBpwMvCptkYVERE9p5WCovLzKOBi23c0LIuIiABaKyiLJf07VUFZKGk74Pn2hhUREb1m\nfAtt3gPMAlbYfkrSFKrLXhEREb/WyhnKwcAy2z+X9E7gbODx9oYVERG9ppWC8v+ApyS9HPgosBK4\ntK1RRUREz2mloKyzbWA28FnbnwW2a29YERHRa1rpQ3lS0pnAicCrJY0DJrQ3rIiI6DWtnKEcDzxD\n9TzKT4DdgAvaGlVERPScEQtKKSKXA5MkHQ08bTt9KBERsZ5Whl55G3A78FbgbcBtko5rd2AREdFb\nWulDOQt4pe2fAUiaBtwAXN3OwCIiore00oeyxUAxKR5tcbuIiNiMtFIY/k3SQknvlvRu4DrgW3Uc\nXNKRkpZJWi7pjCbrJ0q6qqy/TdKMhnVnluXLJL2hjngiImLjjXjJy/ZHJB0L/B7VoJDzbF872gOX\n24+/ABwOrAIWSVpg+66GZu8BHrO9t6Q5wHnA8ZL2A+YA+wO7AjdI2tf2c6ONKyIiNk4rfSjYvga4\npuZjHwQst70CQNJ8qocnGwvKbOCcMn818HlJKsvn234GuE/S8rK//645xoiIaNGQBUXSk4CbrQJs\ne/tRHns34IGGz6uAVw3VxvY6SY8DO5bl3x207W7NDiLpNOA0gOnTp48y5IiIGMqQBcV2u4dXafZO\nlcEFbKg2rWxbLbTnAfMA+vr6mraJiIjR6+bdWquAPRo+7w48NFQbSeOBScCaFreNiIgO6mZBWQTs\nI2mmpC2pOtkXDGqzADipzB8H3FQGqlwAzCl3gc0E9qF6+DIiIrqkpU75dih9Iu8HFgLjgItsL5U0\nF+i3vQD4EnBZ6XRfQ1V0KO2+StWBvw54X+7wiojoLlVf+DcPfX197u/v73YYERE9RdJi230jtevm\nXV4REbEJ6eZdXhERsQlpuQ9F0k7AVgOfbf+4LRFFRERPamX4+jdLuge4D7gFuB/41zbHFRERPaaV\n24Y/Afwu8CPbM4HXAf/V1qgiIqLntFJQnrX9KLCFpC1sfxuY1ea4IiKix7TSh/JzSdsCtwKXS/oZ\n1bMfERERv9bKGcps4JfAB4F/A+4F3tTOoCIiovcM9xzK54ErbH+nYfEl7Q8pIiJ60XBnKPcAn5Z0\nv6TzJKXfJCIihjRkQbH9WdsHA6+lGkfrYkl3S/orSft2LMKIiOgJI/ah2F5p+zzbBwDvAN4C3N32\nyCIioqe08mDjBElvknQ51QONPwKObXtkERHRU4brlD8ceDvwB1TvGpkPnGb7Fx2KLSIieshwz6H8\nJXAF8GHbazoUT0RE9KjhRhs+rJOBREREb+vmK4AjImITkoISERG1SEGJiIhapKBEREQtUlAiIqIW\nKSgREVGLFJSIiKhFCkpERNQiBSUiImqRghIREbVIQYmIiFqkoERERC1SUCIiohYpKBERUYsUlIiI\nqEUKSkRE1CIFJSIiapGCEhERtUhBiYiIWqSgRERELbpSUCRNkXS9pHvKz8lDtDuptLlH0kkNy2+W\ntEzSkjLt1LnoIyKimW6doZwB3Gh7H+DG8nk9kqYAHwdeBRwEfHxQ4TnB9qwy/awTQUdExNC6VVBm\nA5eU+UuAY5q0eQNwve01th8DrgeO7FB8ERGxgbpVUHa2/TBA+dnsktVuwAMNn1eVZQMuLpe7PiZJ\nQx1I0mmS+iX1r169uo7YIyKiifHt2rGkG4AXN1l1Vqu7aLLM5ecJth+UtB1wDXAicGmzndieB8wD\n6Ovrc7M2ERExem0rKLZfP9Q6ST+VtIvthyXtAjTrA1kFHNrweXfg5rLvB8vPJyVdQdXH0rSgRERE\nZ3TrktcCYOCurZOArzdpsxA4QtLk0hl/BLBQ0nhJUwEkTQCOBn7QgZgjImIY3SoonwIOl3QPcHj5\njKQ+SV8EsL0G+ASwqExzy7KJVIXlTmAJ8CDwT51PISIiGsnefLoVJK0GVnY7jg00FXik20F0WHLe\nPCTn3rGn7WkjNdqsCkovktRvu6/bcXRSct48JOdNT4ZeiYiIWqSgRERELVJQxr553Q6gC5Lz5iE5\nb2LShxIREbXIGUpERNQiBSUiImqRgjIGjPb9MA3rF0jqiVEDRpOzpK0lXSfph5KWSvpUZ6PfMJKO\nLO/vWS6p2asaJkq6qqy/TdKMhnVnluXLJL2hk3GPxsbmLOlwSYsl/U/5+fudjn1jjObfuKyfLmmt\npA93Kua2sJ2pyxNwPnBGmT8DOK9JmynAivJzcpmf3LD+D4ErgB90O5925wxsDRxW2mwJ/Afwxm7n\nNESe44B7gb1KrHcA+w1q817gwjI/B7iqzO9X2k8EZpb9jOt2Tm3O+QBg1zL/MuDBbufTznwb1l8D\n/DPw4W7nM5opZyhjw6jeDyNpW+BDwCc7EGtdNjpn20/Z/jaA7V8B36MaPHQsOghYbntFiXU+Ve6N\nGn8XVwOvK69kmA3Mt/2M7fuA5WV/Y91G52z7+7YfKsuXAltJmtiRqDfeaP6NkXQM1ZelpR2Kt21S\nUMaG0b4f5hPAp4Gn2hlkzep4Jw6SdgDeRPXmz7FoxBwa29heBzwO7NjitmPRaHJudCzwfdvPtCnO\numx0vpK2Af4COLcDcbZd24avj/W16/0wkmYBe9v+4ODrst3W5nfiIGk8cCXwOdsrNjzCjhg2hxHa\ntLLtWDSanKuV0v7AeVSjjI91o8n3XODvbK8d5j2BPSMFpUPcvvfDHAwcKOl+qn/PnSTdbPtQuqyN\nOQ+YB9xj+zM1hNsuq4A9Gj7vDjw0RJtVpUhOAta0uO1YNJqckbQ7cC3wLtv3tj/cURtNvq8CjpN0\nPrAD8Lykp21/vv1ht0G3O3EyGeAC1u+gPr9JmynAfVSd0pPL/JRBbWbQO53yo8qZqr/oGmCLbucy\nQp7jqa6Pz+SFDtv9B7V5H+t32H61zO/P+p3yK+iNTvnR5LxDaX9st/PoRL6D2pxDj3fKdz2ATIbq\n2vGNwD3l58AfzT7giw3tTqHqmF0OnNxkP71UUDY6Z6pvgAbupnonzhLg1G7nNEyuRwE/oroT6Kyy\nbC7w5jK/FdUdPsuB24G9GrY9q2y3jDF6J1udOQNnA79o+HddAuzU7Xza+W/csI+eLygZeiUiImqR\nu7wiIqIWKSgREVGLFJSIiKhFCkpERNQiBSUiImqRghI9TdLNg0fhlfRnkv5hhO3WbsjyzYGkQyV9\ns9txRO9KQYledyXVg2KN5pTlEdFBKSjR664Gjh4YkbaMZ7Yr8J+StpV0o6TvlfdrDB4BdkiqXCDp\nB2Xb48vyXSTdKmlJWfdqSeMkfbmh7QcH7WuSpPslbVE+by3pAUkTJP2ppLsk3SlpfgtxvVPS7eX4\n/yhpXFm+VtKnS643SppWls+S9N2y/2tV3jsjaW9JN0i6o2zzknKIbSVdrepdM5c3jIh7oKRbyjtK\nFpbhctjQ+GMT1+0nKzNlGu0EXAfMLvNnABeU+fHA9mV+KtVTygMP864dYl9ry89jqYbLHwfsDPwY\n2AX4c154EnocsB1wINUw+wP72KHJfr/OC+9wOZ4yGgDVmE8Th9pu0D5+G/gGMKF8/geq8a6gGjng\nhDL/V8Dny/ydwGvL/FzgM2X+NuAtZX4rqnfMHEo1Cu7uVF82/xs4BJgAfAeY1hD/RRsaf6ZNf8oZ\nSmwKGi97NV7uEvDXku4EbqAaQnznFvd5CHCl7eds/xS4BXglsAg4WdI5wO/YfpJqHKe9JP29pCOB\nJ5rs7yqqP8QDMV5V5u8ELpf0TmDdCDG9jqp4LZK0pHzeq6x7vmGfXwEOkTSJ6o/8LWX5JcBrJG0H\n7Gb7WgDbT9seePXB7bZX2X6eatiTGcBLqV52dX057tm88P6ZDYk/NnEpKLEp+BrVC4teAbzI9vfK\n8hOAacCBtmcBP6X6Nt6KpmOJ274VeA3wIHCZpHe5evnXy6lGQn4f8MUmmy4A3ihpClVRuKks/wPg\nC2XZ4jIS7XAxXWJ7VpleavucIdoON6bScOOkN7575DmqszwBSxuO+zu2B4aV35D4YxOXghI9z/Za\nqj/mF7F+Z/wk4Ge2n5V0GLDnBuz2VuD40j8yjaqI3C5pz7LPfwK+BLxC0lSqUY+vAT4GvGKIGG8H\nPgt80/ZzpU9lD1dvn/wo1Ui72w4T041UQ53vBCBpSokHqv+Xjyvz7wD+0/bjwGOSXl2WnwjcYvsJ\nqmHUjyn7mShp62GOuwyYJumZabaGAAAA6klEQVTg0n6CpP03Iv7YxOXbRGwqrgT+hfXv+Loc+Iak\nfqrLNz/cgP1dS/WumTuovu1/1PZPJJ0EfETSs8Ba4F1Ul9IuHuh0B84cYp9XUY04e2j5PA74Srk0\nJaoXLf1cUh9wuu1TGze2fZeks4F/L8d6luqMaCXVCL37S1pM1Q8ycHntJODCUjBWACeX5ScC/yhp\nbtnPW4f6Rdj+laTjgM+VWMcDn6EaXfc34h9qP7Hpy2jDEZsASWtt5+wguiqXvCIiohY5Q4mIiFrk\nDCUiImqRghIREbVIQYmIiFqkoERERC1SUCIiohb/H8kC+n3YIhDhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_list, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#超参数lambda\n",
    "lamba = 0.2\n",
    "batch_size2=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class Change(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Change, self).__init__()\n",
    "        #特征融合\n",
    "        self.score_fc = torch.nn.Conv1d(64, 2, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = x#[10, 64]\n",
    "        output = output.unsqueeze(2)\n",
    "        score = self.score_fc(output)\n",
    "        offset_pred = score.squeeze(2)\n",
    "        return offset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_CNN()\n",
    "Loss = nn.MSELoss()\n",
    "model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_params.pkl'))\n",
    "x1 = Variable(torch.LongTensor(x_batch_train[:10]))\n",
    "x2 = Variable(torch.FloatTensor(x_csv_train[:10]))\n",
    "x3 = Variable(torch.FloatTensor(target_list_train[:10]))\n",
    "print(\"target.shape: \"+str(x3.shape))\n",
    "print(x3)\n",
    "y = Variable(torch.FloatTensor(y_csv_train[:10]))\n",
    "pred = model(x1, x2)\n",
    "change_model = Change()\n",
    "pred2 = change_model(pred)\n",
    "print(\"pred2.shape: \"+str(pred2.shape))\n",
    "print(pred2)\n",
    "loss = Loss(pred2, x3)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_2_list=[]\n",
    "val_loss_2_list=[]\n",
    "resualt_text_path='C:/Users/wuxun/Desktop/resualt.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_2(optimizer, change_model, scheduler):\n",
    "    model = LSTM_CNN()\n",
    "    Loss = nn.MSELoss()\n",
    "    model.load_state_dict(torch.load('C:/Users/wuxun/Des ktop/Data/save_model/189epoch_20200713_params.pkl'))\n",
    "    best_val_loss_2 = 1000000\n",
    "    print(\"train begin......\")\n",
    "    with open(resualt_text_path,'a') as f:\n",
    "        for epoch in range(200):\n",
    "            batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, batch_size2)\n",
    "            count = 0\n",
    "            train_loss_sum = 0\n",
    "            train_loss_avg = 0\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_train:\n",
    "                if x_csv.shape[0]==batch_size2:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                    target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "\n",
    "                    pred = model(x1, x2)\n",
    "                    pred2 = change_model(pred)\n",
    "                    \n",
    "                    loss_reg = torch.sqrt(Loss(pred2, target_time))\n",
    "                    train_loss_sum +=loss_reg\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            scheduler.step()\n",
    "            train_loss_avg = train_loss_sum /count\n",
    "            print(\"[epoch: \"+str(epoch)+\" ]   loss= \"+str(train_loss_avg)+\" lr = %f\" % (optimizer.param_groups[0]['lr']))\n",
    "            train_loss_2_list.append(train_loss_avg)\n",
    "\n",
    "            if (epoch+1)%5==0:\n",
    "                print(\"进行验证.......\")\n",
    "                batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size2)\n",
    "                count = 0\n",
    "                val_loss_sum = 0\n",
    "                val_loss_avg = 0 \n",
    "                for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                    if x_csv.shape[0]==batch_size2:\n",
    "                        count += 1\n",
    "                        x1 = Variable(torch.LongTensor(x_batch))\n",
    "                        x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                        source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                        target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "\n",
    "                        pred = model(x1, x2)\n",
    "                        pred2 = change_model(pred)\n",
    "                        loss_reg = torch.sqrt(Loss(pred2, target_time))\n",
    "\n",
    "                        val_loss_sum +=loss_reg\n",
    "                        optimizer.zero_grad()\n",
    "                        loss_reg.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                scheduler.step()\n",
    "                val_loss_avg = val_loss_sum / count\n",
    "                print(\"[epoch: \"+str(epoch)+\" ]   loss= \"+str(val_loss_avg)+\" lr = %f\" % (optimizer.param_groups[0]['lr']))\n",
    "                val_loss_2_list.append(val_loss_avg) \n",
    "                torch.save(change_model.state_dict(), 'C:/Users/wuxun/Desktop/Data/save_model2/epoch'+str(epoch)+'_batchsize1_params.pkl')\n",
    "                if val_loss_avg < best_val_loss_2:\n",
    "                    torch.save(change_model.state_dict(), save_path2)\n",
    "                    best_val_loss_2 = val_loss_avg\n",
    "                    print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率调整策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, lr_policy):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "        Parameters:\n",
    "        optimizer -- 网络优化器\n",
    "        opt.lr_policy -- 学习率scheduler的名称: linear | step | plateau | cosine\n",
    "    \"\"\"\n",
    "    if lr_policy == 'linear':\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "    elif lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0)\n",
    "    else:\n",
    "        print('learning rate policy [%s] is not implemented'%(lr_policy))\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义回归模型与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_model = Change()\n",
    "initial_lr = 0.1\n",
    "optimizer = optim.Adam(change_model.parameters(), lr = initial_lr)\n",
    "scheduler = get_scheduler(optimizer, 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train begin......\n",
      "[epoch: 0 ]   loss= tensor(169.233062744140625, grad_fn=<DivBackward0>) lr = 0.100000\n",
      "[epoch: 1 ]   loss= tensor(163.440750122070312, grad_fn=<DivBackward0>) lr = 0.050000\n",
      "[epoch: 2 ]   loss= tensor(158.141555786132812, grad_fn=<DivBackward0>) lr = 0.033333\n",
      "[epoch: 3 ]   loss= tensor(156.086654663085938, grad_fn=<DivBackward0>) lr = 0.025000\n",
      "[epoch: 4 ]   loss= tensor(155.096740722656250, grad_fn=<DivBackward0>) lr = 0.020000\n",
      "进行验证.......\n",
      "[epoch: 4 ]   loss= tensor(152.550445556640625, grad_fn=<DivBackward0>) lr = 0.016667\n",
      "model save!\n",
      "[epoch: 5 ]   loss= tensor(154.396194458007812, grad_fn=<DivBackward0>) lr = 0.014286\n",
      "[epoch: 6 ]   loss= tensor(152.676574707031250, grad_fn=<DivBackward0>) lr = 0.012500\n",
      "[epoch: 7 ]   loss= tensor(152.609848022460938, grad_fn=<DivBackward0>) lr = 0.011111\n",
      "[epoch: 8 ]   loss= tensor(153.930709838867188, grad_fn=<DivBackward0>) lr = 0.010000\n",
      "[epoch: 9 ]   loss= tensor(150.360565185546875, grad_fn=<DivBackward0>) lr = 0.009091\n",
      "进行验证.......\n",
      "[epoch: 9 ]   loss= tensor(149.539779663085938, grad_fn=<DivBackward0>) lr = 0.008333\n",
      "model save!\n",
      "[epoch: 10 ]   loss= tensor(155.042251586914062, grad_fn=<DivBackward0>) lr = 0.007692\n",
      "[epoch: 11 ]   loss= tensor(150.727691650390625, grad_fn=<DivBackward0>) lr = 0.007143\n",
      "[epoch: 12 ]   loss= tensor(151.245590209960938, grad_fn=<DivBackward0>) lr = 0.006667\n",
      "[epoch: 13 ]   loss= tensor(151.091384887695312, grad_fn=<DivBackward0>) lr = 0.006250\n",
      "[epoch: 14 ]   loss= tensor(150.630081176757812, grad_fn=<DivBackward0>) lr = 0.005882\n",
      "进行验证.......\n",
      "[epoch: 14 ]   loss= tensor(150.028533935546875, grad_fn=<DivBackward0>) lr = 0.005556\n",
      "[epoch: 15 ]   loss= tensor(152.809020996093750, grad_fn=<DivBackward0>) lr = 0.005263\n",
      "[epoch: 16 ]   loss= tensor(150.573577880859375, grad_fn=<DivBackward0>) lr = 0.005000\n",
      "[epoch: 17 ]   loss= tensor(151.554214477539062, grad_fn=<DivBackward0>) lr = 0.004762\n",
      "[epoch: 18 ]   loss= tensor(150.773910522460938, grad_fn=<DivBackward0>) lr = 0.004545\n",
      "[epoch: 19 ]   loss= tensor(149.519058227539062, grad_fn=<DivBackward0>) lr = 0.004348\n",
      "进行验证.......\n",
      "[epoch: 19 ]   loss= tensor(148.391998291015625, grad_fn=<DivBackward0>) lr = 0.004167\n",
      "model save!\n",
      "[epoch: 20 ]   loss= tensor(151.504516601562500, grad_fn=<DivBackward0>) lr = 0.004000\n",
      "[epoch: 21 ]   loss= tensor(152.289321899414062, grad_fn=<DivBackward0>) lr = 0.003846\n",
      "[epoch: 22 ]   loss= tensor(151.527297973632812, grad_fn=<DivBackward0>) lr = 0.003704\n",
      "[epoch: 23 ]   loss= tensor(150.216339111328125, grad_fn=<DivBackward0>) lr = 0.003571\n",
      "[epoch: 24 ]   loss= tensor(150.550384521484375, grad_fn=<DivBackward0>) lr = 0.003448\n",
      "进行验证.......\n",
      "[epoch: 24 ]   loss= tensor(148.623764038085938, grad_fn=<DivBackward0>) lr = 0.003333\n",
      "[epoch: 25 ]   loss= tensor(149.006362915039062, grad_fn=<DivBackward0>) lr = 0.003226\n",
      "[epoch: 26 ]   loss= tensor(151.244400024414062, grad_fn=<DivBackward0>) lr = 0.003125\n",
      "[epoch: 27 ]   loss= tensor(147.903518676757812, grad_fn=<DivBackward0>) lr = 0.003030\n",
      "[epoch: 28 ]   loss= tensor(151.110473632812500, grad_fn=<DivBackward0>) lr = 0.002941\n",
      "[epoch: 29 ]   loss= tensor(149.667251586914062, grad_fn=<DivBackward0>) lr = 0.002857\n",
      "进行验证.......\n",
      "[epoch: 29 ]   loss= tensor(146.186431884765625, grad_fn=<DivBackward0>) lr = 0.002778\n",
      "model save!\n",
      "[epoch: 30 ]   loss= tensor(149.410263061523438, grad_fn=<DivBackward0>) lr = 0.002703\n",
      "[epoch: 31 ]   loss= tensor(150.223037719726562, grad_fn=<DivBackward0>) lr = 0.002632\n",
      "[epoch: 32 ]   loss= tensor(151.077835083007812, grad_fn=<DivBackward0>) lr = 0.002564\n",
      "[epoch: 33 ]   loss= tensor(149.561981201171875, grad_fn=<DivBackward0>) lr = 0.002500\n",
      "[epoch: 34 ]   loss= tensor(150.498535156250000, grad_fn=<DivBackward0>) lr = 0.002439\n",
      "进行验证.......\n",
      "[epoch: 34 ]   loss= tensor(146.891021728515625, grad_fn=<DivBackward0>) lr = 0.002381\n",
      "[epoch: 35 ]   loss= tensor(150.247360229492188, grad_fn=<DivBackward0>) lr = 0.002326\n",
      "[epoch: 36 ]   loss= tensor(149.854904174804688, grad_fn=<DivBackward0>) lr = 0.002273\n",
      "[epoch: 37 ]   loss= tensor(148.953842163085938, grad_fn=<DivBackward0>) lr = 0.002222\n",
      "[epoch: 38 ]   loss= tensor(150.058013916015625, grad_fn=<DivBackward0>) lr = 0.002174\n",
      "[epoch: 39 ]   loss= tensor(147.571273803710938, grad_fn=<DivBackward0>) lr = 0.002128\n",
      "进行验证.......\n",
      "[epoch: 39 ]   loss= tensor(147.303268432617188, grad_fn=<DivBackward0>) lr = 0.002083\n",
      "[epoch: 40 ]   loss= tensor(148.632369995117188, grad_fn=<DivBackward0>) lr = 0.002041\n",
      "[epoch: 41 ]   loss= tensor(150.952285766601562, grad_fn=<DivBackward0>) lr = 0.002000\n",
      "[epoch: 42 ]   loss= tensor(150.533386230468750, grad_fn=<DivBackward0>) lr = 0.001961\n",
      "[epoch: 43 ]   loss= tensor(151.322799682617188, grad_fn=<DivBackward0>) lr = 0.001923\n",
      "[epoch: 44 ]   loss= tensor(147.928604125976562, grad_fn=<DivBackward0>) lr = 0.001887\n",
      "进行验证.......\n",
      "[epoch: 44 ]   loss= tensor(148.644561767578125, grad_fn=<DivBackward0>) lr = 0.001852\n",
      "[epoch: 45 ]   loss= tensor(150.379608154296875, grad_fn=<DivBackward0>) lr = 0.001818\n",
      "[epoch: 46 ]   loss= tensor(150.261947631835938, grad_fn=<DivBackward0>) lr = 0.001786\n",
      "[epoch: 47 ]   loss= tensor(148.598022460937500, grad_fn=<DivBackward0>) lr = 0.001754\n",
      "[epoch: 48 ]   loss= tensor(148.273513793945312, grad_fn=<DivBackward0>) lr = 0.001724\n",
      "[epoch: 49 ]   loss= tensor(150.014663696289062, grad_fn=<DivBackward0>) lr = 0.001695\n",
      "进行验证.......\n",
      "[epoch: 49 ]   loss= tensor(149.203399658203125, grad_fn=<DivBackward0>) lr = 0.001667\n",
      "[epoch: 50 ]   loss= tensor(149.481643676757812, grad_fn=<DivBackward0>) lr = 0.001639\n",
      "[epoch: 51 ]   loss= tensor(149.314300537109375, grad_fn=<DivBackward0>) lr = 0.001613\n",
      "[epoch: 52 ]   loss= tensor(149.309600830078125, grad_fn=<DivBackward0>) lr = 0.001587\n",
      "[epoch: 53 ]   loss= tensor(148.689849853515625, grad_fn=<DivBackward0>) lr = 0.001563\n",
      "[epoch: 54 ]   loss= tensor(148.277114868164062, grad_fn=<DivBackward0>) lr = 0.001538\n",
      "进行验证.......\n",
      "[epoch: 54 ]   loss= tensor(150.122283935546875, grad_fn=<DivBackward0>) lr = 0.001515\n",
      "[epoch: 55 ]   loss= tensor(148.848007202148438, grad_fn=<DivBackward0>) lr = 0.001493\n",
      "[epoch: 56 ]   loss= tensor(148.581649780273438, grad_fn=<DivBackward0>) lr = 0.001471\n",
      "[epoch: 57 ]   loss= tensor(150.014282226562500, grad_fn=<DivBackward0>) lr = 0.001449\n",
      "[epoch: 58 ]   loss= tensor(149.340179443359375, grad_fn=<DivBackward0>) lr = 0.001429\n",
      "[epoch: 59 ]   loss= tensor(152.579513549804688, grad_fn=<DivBackward0>) lr = 0.001408\n",
      "进行验证.......\n",
      "[epoch: 59 ]   loss= tensor(149.110214233398438, grad_fn=<DivBackward0>) lr = 0.001389\n",
      "[epoch: 60 ]   loss= tensor(148.572128295898438, grad_fn=<DivBackward0>) lr = 0.001370\n",
      "[epoch: 61 ]   loss= tensor(149.008438110351562, grad_fn=<DivBackward0>) lr = 0.001351\n",
      "[epoch: 62 ]   loss= tensor(150.736236572265625, grad_fn=<DivBackward0>) lr = 0.001333\n",
      "[epoch: 63 ]   loss= tensor(149.782836914062500, grad_fn=<DivBackward0>) lr = 0.001316\n",
      "[epoch: 64 ]   loss= tensor(149.488388061523438, grad_fn=<DivBackward0>) lr = 0.001299\n",
      "进行验证.......\n",
      "[epoch: 64 ]   loss= tensor(146.671646118164062, grad_fn=<DivBackward0>) lr = 0.001282\n",
      "[epoch: 65 ]   loss= tensor(148.224578857421875, grad_fn=<DivBackward0>) lr = 0.001266\n",
      "[epoch: 66 ]   loss= tensor(149.286590576171875, grad_fn=<DivBackward0>) lr = 0.001250\n",
      "[epoch: 67 ]   loss= tensor(150.324676513671875, grad_fn=<DivBackward0>) lr = 0.001235\n",
      "[epoch: 68 ]   loss= tensor(150.130340576171875, grad_fn=<DivBackward0>) lr = 0.001220\n",
      "[epoch: 69 ]   loss= tensor(150.177429199218750, grad_fn=<DivBackward0>) lr = 0.001205\n",
      "进行验证.......\n",
      "[epoch: 69 ]   loss= tensor(147.633605957031250, grad_fn=<DivBackward0>) lr = 0.001190\n",
      "[epoch: 70 ]   loss= tensor(148.471420288085938, grad_fn=<DivBackward0>) lr = 0.001176\n",
      "[epoch: 71 ]   loss= tensor(150.274978637695312, grad_fn=<DivBackward0>) lr = 0.001163\n",
      "[epoch: 72 ]   loss= tensor(150.612136840820312, grad_fn=<DivBackward0>) lr = 0.001149\n",
      "[epoch: 73 ]   loss= tensor(148.202682495117188, grad_fn=<DivBackward0>) lr = 0.001136\n",
      "[epoch: 74 ]   loss= tensor(147.888366699218750, grad_fn=<DivBackward0>) lr = 0.001124\n",
      "进行验证.......\n",
      "[epoch: 74 ]   loss= tensor(146.062820434570312, grad_fn=<DivBackward0>) lr = 0.001111\n",
      "model save!\n",
      "[epoch: 75 ]   loss= tensor(149.667755126953125, grad_fn=<DivBackward0>) lr = 0.001099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 76 ]   loss= tensor(148.649093627929688, grad_fn=<DivBackward0>) lr = 0.001087\n",
      "[epoch: 77 ]   loss= tensor(149.404388427734375, grad_fn=<DivBackward0>) lr = 0.001075\n",
      "[epoch: 78 ]   loss= tensor(147.427688598632812, grad_fn=<DivBackward0>) lr = 0.001064\n",
      "[epoch: 79 ]   loss= tensor(147.642333984375000, grad_fn=<DivBackward0>) lr = 0.001053\n",
      "进行验证.......\n",
      "[epoch: 79 ]   loss= tensor(146.624862670898438, grad_fn=<DivBackward0>) lr = 0.001042\n",
      "[epoch: 80 ]   loss= tensor(149.265808105468750, grad_fn=<DivBackward0>) lr = 0.001031\n",
      "[epoch: 81 ]   loss= tensor(150.212707519531250, grad_fn=<DivBackward0>) lr = 0.001020\n",
      "[epoch: 82 ]   loss= tensor(149.065414428710938, grad_fn=<DivBackward0>) lr = 0.001010\n",
      "[epoch: 83 ]   loss= tensor(148.764450073242188, grad_fn=<DivBackward0>) lr = 0.001000\n",
      "[epoch: 84 ]   loss= tensor(148.970336914062500, grad_fn=<DivBackward0>) lr = 0.000990\n",
      "进行验证.......\n",
      "[epoch: 84 ]   loss= tensor(146.058792114257812, grad_fn=<DivBackward0>) lr = 0.000980\n",
      "model save!\n",
      "[epoch: 85 ]   loss= tensor(150.243942260742188, grad_fn=<DivBackward0>) lr = 0.000971\n",
      "[epoch: 86 ]   loss= tensor(148.627883911132812, grad_fn=<DivBackward0>) lr = 0.000962\n",
      "[epoch: 87 ]   loss= tensor(148.792282104492188, grad_fn=<DivBackward0>) lr = 0.000952\n",
      "[epoch: 88 ]   loss= tensor(149.791091918945312, grad_fn=<DivBackward0>) lr = 0.000943\n",
      "[epoch: 89 ]   loss= tensor(146.764160156250000, grad_fn=<DivBackward0>) lr = 0.000935\n",
      "进行验证.......\n",
      "[epoch: 89 ]   loss= tensor(147.408737182617188, grad_fn=<DivBackward0>) lr = 0.000926\n",
      "[epoch: 90 ]   loss= tensor(148.658279418945312, grad_fn=<DivBackward0>) lr = 0.000917\n",
      "[epoch: 91 ]   loss= tensor(150.701385498046875, grad_fn=<DivBackward0>) lr = 0.000909\n",
      "[epoch: 92 ]   loss= tensor(149.274597167968750, grad_fn=<DivBackward0>) lr = 0.000901\n",
      "[epoch: 93 ]   loss= tensor(148.130081176757812, grad_fn=<DivBackward0>) lr = 0.000893\n",
      "[epoch: 94 ]   loss= tensor(148.137924194335938, grad_fn=<DivBackward0>) lr = 0.000885\n",
      "进行验证.......\n",
      "[epoch: 94 ]   loss= tensor(146.007232666015625, grad_fn=<DivBackward0>) lr = 0.000877\n",
      "model save!\n",
      "[epoch: 95 ]   loss= tensor(148.165420532226562, grad_fn=<DivBackward0>) lr = 0.000870\n",
      "[epoch: 96 ]   loss= tensor(148.176559448242188, grad_fn=<DivBackward0>) lr = 0.000862\n",
      "[epoch: 97 ]   loss= tensor(147.604919433593750, grad_fn=<DivBackward0>) lr = 0.000855\n",
      "[epoch: 98 ]   loss= tensor(149.295089721679688, grad_fn=<DivBackward0>) lr = 0.000847\n",
      "[epoch: 99 ]   loss= tensor(149.514968872070312, grad_fn=<DivBackward0>) lr = 0.000840\n",
      "进行验证.......\n",
      "[epoch: 99 ]   loss= tensor(145.164199829101562, grad_fn=<DivBackward0>) lr = 0.000833\n",
      "model save!\n",
      "[epoch: 100 ]   loss= tensor(149.093429565429688, grad_fn=<DivBackward0>) lr = 0.000826\n",
      "[epoch: 101 ]   loss= tensor(148.481475830078125, grad_fn=<DivBackward0>) lr = 0.000820\n",
      "[epoch: 102 ]   loss= tensor(149.145858764648438, grad_fn=<DivBackward0>) lr = 0.000813\n",
      "[epoch: 103 ]   loss= tensor(149.013687133789062, grad_fn=<DivBackward0>) lr = 0.000806\n",
      "[epoch: 104 ]   loss= tensor(148.406555175781250, grad_fn=<DivBackward0>) lr = 0.000800\n",
      "进行验证.......\n",
      "[epoch: 104 ]   loss= tensor(146.509704589843750, grad_fn=<DivBackward0>) lr = 0.000794\n",
      "[epoch: 105 ]   loss= tensor(147.501388549804688, grad_fn=<DivBackward0>) lr = 0.000787\n",
      "[epoch: 106 ]   loss= tensor(149.021163940429688, grad_fn=<DivBackward0>) lr = 0.000781\n",
      "[epoch: 107 ]   loss= tensor(148.311172485351562, grad_fn=<DivBackward0>) lr = 0.000775\n",
      "[epoch: 108 ]   loss= tensor(147.209838867187500, grad_fn=<DivBackward0>) lr = 0.000769\n",
      "[epoch: 109 ]   loss= tensor(148.056747436523438, grad_fn=<DivBackward0>) lr = 0.000763\n",
      "进行验证.......\n",
      "[epoch: 109 ]   loss= tensor(144.147018432617188, grad_fn=<DivBackward0>) lr = 0.000758\n",
      "model save!\n",
      "[epoch: 110 ]   loss= tensor(146.690536499023438, grad_fn=<DivBackward0>) lr = 0.000752\n",
      "[epoch: 111 ]   loss= tensor(147.136093139648438, grad_fn=<DivBackward0>) lr = 0.000746\n",
      "[epoch: 112 ]   loss= tensor(146.669738769531250, grad_fn=<DivBackward0>) lr = 0.000741\n",
      "[epoch: 113 ]   loss= tensor(148.100891113281250, grad_fn=<DivBackward0>) lr = 0.000735\n",
      "[epoch: 114 ]   loss= tensor(148.376235961914062, grad_fn=<DivBackward0>) lr = 0.000730\n",
      "进行验证.......\n",
      "[epoch: 114 ]   loss= tensor(146.991378784179688, grad_fn=<DivBackward0>) lr = 0.000725\n",
      "[epoch: 115 ]   loss= tensor(149.569396972656250, grad_fn=<DivBackward0>) lr = 0.000719\n",
      "[epoch: 116 ]   loss= tensor(148.378372192382812, grad_fn=<DivBackward0>) lr = 0.000714\n",
      "[epoch: 117 ]   loss= tensor(148.275299072265625, grad_fn=<DivBackward0>) lr = 0.000709\n",
      "[epoch: 118 ]   loss= tensor(147.395462036132812, grad_fn=<DivBackward0>) lr = 0.000704\n",
      "[epoch: 119 ]   loss= tensor(149.083938598632812, grad_fn=<DivBackward0>) lr = 0.000699\n",
      "进行验证.......\n",
      "[epoch: 119 ]   loss= tensor(145.369720458984375, grad_fn=<DivBackward0>) lr = 0.000694\n",
      "[epoch: 120 ]   loss= tensor(149.322280883789062, grad_fn=<DivBackward0>) lr = 0.000690\n",
      "[epoch: 121 ]   loss= tensor(147.998458862304688, grad_fn=<DivBackward0>) lr = 0.000685\n",
      "[epoch: 122 ]   loss= tensor(149.654815673828125, grad_fn=<DivBackward0>) lr = 0.000680\n",
      "[epoch: 123 ]   loss= tensor(147.857681274414062, grad_fn=<DivBackward0>) lr = 0.000676\n",
      "[epoch: 124 ]   loss= tensor(147.997436523437500, grad_fn=<DivBackward0>) lr = 0.000671\n",
      "进行验证.......\n",
      "[epoch: 124 ]   loss= tensor(146.480133056640625, grad_fn=<DivBackward0>) lr = 0.000667\n",
      "[epoch: 125 ]   loss= tensor(148.462249755859375, grad_fn=<DivBackward0>) lr = 0.000662\n",
      "[epoch: 126 ]   loss= tensor(148.550643920898438, grad_fn=<DivBackward0>) lr = 0.000658\n",
      "[epoch: 127 ]   loss= tensor(149.024414062500000, grad_fn=<DivBackward0>) lr = 0.000654\n",
      "[epoch: 128 ]   loss= tensor(148.688735961914062, grad_fn=<DivBackward0>) lr = 0.000649\n",
      "[epoch: 129 ]   loss= tensor(150.809616088867188, grad_fn=<DivBackward0>) lr = 0.000645\n",
      "进行验证.......\n",
      "[epoch: 129 ]   loss= tensor(146.251586914062500, grad_fn=<DivBackward0>) lr = 0.000641\n",
      "[epoch: 130 ]   loss= tensor(148.045791625976562, grad_fn=<DivBackward0>) lr = 0.000637\n",
      "[epoch: 131 ]   loss= tensor(147.784469604492188, grad_fn=<DivBackward0>) lr = 0.000633\n",
      "[epoch: 132 ]   loss= tensor(147.937637329101562, grad_fn=<DivBackward0>) lr = 0.000629\n",
      "[epoch: 133 ]   loss= tensor(149.815795898437500, grad_fn=<DivBackward0>) lr = 0.000625\n",
      "[epoch: 134 ]   loss= tensor(148.489242553710938, grad_fn=<DivBackward0>) lr = 0.000621\n",
      "进行验证.......\n",
      "[epoch: 134 ]   loss= tensor(146.382095336914062, grad_fn=<DivBackward0>) lr = 0.000617\n",
      "[epoch: 135 ]   loss= tensor(148.820678710937500, grad_fn=<DivBackward0>) lr = 0.000613\n",
      "[epoch: 136 ]   loss= tensor(147.286270141601562, grad_fn=<DivBackward0>) lr = 0.000610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-e46545b320a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-90-be9f039aa123>\u001b[0m in \u001b[0;36mtrain_2\u001b[1;34m(optimizer, change_model, scheduler)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mtarget_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                     \u001b[0mpred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-aa6155c8e9a5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#lstm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_2(optimizer, change_model, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_2_list, val_loss_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTM_CNN()\n",
    "Loss = nn.MSELoss()\n",
    "model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/189epoch_20200713_params.pkl'))\n",
    "x1 = Variable(torch.LongTensor(x_batch_train[:10]))\n",
    "x2 = Variable(torch.FloatTensor(x_csv_train[:10]))\n",
    "x3 = Variable(torch.FloatTensor(target_list_train[:10]))\n",
    "print(\"target.shape: \"+str(x3.shape))\n",
    "print(x3)\n",
    "y = Variable(torch.FloatTensor(y_csv_train[:10]))\n",
    "pred = model(x1, x2)\n",
    "change_model = Change()\n",
    "pred2 = change_model(pred)\n",
    "print(\"pred2.shape: \"+str(pred2.shape))\n",
    "print(pred2)\n",
    "loss = Loss(pred2, x3)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算R@1在tIOU为0.1/0.3/0.5/0.7的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_IoU(i0,i1):\n",
    "    union = (min(i0[0], i1[0]), max(i0[1], i1[1]))\n",
    "    inter = (max(i0[0], i1[0]), min(i0[1], i1[1]))\n",
    "    iou = 1.0*(inter[1]-inter[0])/(union[1]-union[0])\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "compute recall at certain IoU\n",
    "'''\n",
    "def compute_IoU_recall_top_n_forreg(top_n, iou_thresh, sentence_image_mat, sentence_image_reg_mat, sclips, iclips):\n",
    "    correct_num = 0.0\n",
    "    for k in range(sentence_image_mat.shape[0]):\n",
    "        gt = sclips[k]\n",
    "        gt_start = float(gt.split(\"_\")[1])\n",
    "        gt_end = float(gt.split(\"_\")[2])\n",
    "        sim_v = [v for v in sentence_image_mat[k]]\n",
    "        starts = [s for s in sentence_image_reg_mat[k,:,0]]\n",
    "        ends = [e for e in sentence_image_reg_mat[k,:,1]]\n",
    "        picks = nms_temporal(starts,ends, sim_v, iou_thresh-0.05)\n",
    "        #sim_argsort=np.argsort(sim_v)[::-1][0:top_n]\n",
    "        if top_n<len(picks): picks=picks[0:top_n]\n",
    "        for index in picks:\n",
    "            pred_start = sentence_image_reg_mat[k, index, 0]\n",
    "            pred_end = sentence_image_reg_mat[k, index, 1]\n",
    "            iou = calculate_IoU((gt_start, gt_end),(pred_start, pred_end))\n",
    "            if iou>=iou_thresh:\n",
    "                correct_num+=1\n",
    "                break\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAL_测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = []\n",
    "resualt_text_path='C:/Users/wuxun/Desktop/resulat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_3():\n",
    "    change_model = Change()\n",
    "    model = LSTM_CNN()\n",
    "    model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/60poch_20200713_params.pkl'))\n",
    "    optimizer = optim.Adam(change_model.parameters(), lr = 0.001)\n",
    "    best_val_loss_2 = 1000000\n",
    "    print(\"train begin......\")\n",
    "    with open(resualt_text_path,'a') as f:\n",
    " \n",
    "        for epoch in range(200):\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, batch_size)\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            val_loss_avg = 0 \n",
    "            val_alignmentloss_sum =0\n",
    "            val_regloss_sum =0\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time in batch_val:\n",
    "                if x_csv.shape[0]==batch_size:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                    target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                    pred = model(x1, x2)\n",
    "                    pred2, loss_alignment = change_model(pred)\n",
    "\n",
    "                    loss_reg = torch.abs(pred2 - target_time).mean()\n",
    "                    for i in range(pred2.shape[0]):\n",
    "                        f.write('target_time:[%d, %d]      (l_reg, r_reg):[%.3f, %.3f]\\n' %(target_time[i][0],target_time[i][1],pred2[i][0], pred2[i][1]))\n",
    "                        #print('target_time:[%d, %d]  (l_reg, r_reg):[%.3f, %.3f]' %(target_time[i][0],target_time[i][1],pred2[i][0], pred2[i][1]))\n",
    "                    val_regloss_sum +=loss_reg\n",
    "                    loss_reg = loss_reg*lamba + loss_alignment\n",
    "\n",
    "                    val_loss_sum +=loss_reg\n",
    "                    val_alignmentloss_sum += loss_alignment\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_reg.backward()\n",
    "                    nn.utils.clip_grad_norm_(change_model.parameters(), max_norm=20, norm_type=2)#梯度裁剪\n",
    "                    optimizer.step()\n",
    "\n",
    "            val_loss_avg = val_loss_sum / count\n",
    "            f.write(\"======================================================================================\\n\")\n",
    "            #print(\"============================================================================\")\n",
    "            #print(\"epoch\"+str(epoch)+\": sum_loss:\"+str((val_loss_avg))+\"  loss_alignment: \"+str(val_alignmentloss_sum/count)+\"  loss_reg: \"+str(val_regloss_sum/count))\n",
    "            f.write('[epoch:%d]     sum_loss: %.3f     loss_alignment: %.3f    loss_reg: %.3f\\n' %(epoch, val_loss_avg, val_alignmentloss_sum/count, val_regloss_sum/count))\n",
    "            print('[epoch:%d]   sum_loss: %.3f   loss_alignment: %.3f  loss_reg: %.3f' %(epoch, val_loss_avg, val_alignmentloss_sum/count, val_regloss_sum/count))\n",
    "            val.append(val_loss_avg)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
