{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TALL模型实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime  # 用于计算时间\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#import tensorflow.contrib.keras as kr\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from torchtext import data\n",
    "import jieba\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=15)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/TALL/traning/training.txt'\n",
    "val_path = './data/TALL/validation/validation.txt'\n",
    "vocab_dir = './data/vocab.txt'\n",
    "csv_path = './data/csv/'\n",
    "save_path = './data/TALL/save_model/'\n",
    "test_path = './data/TALL/testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(vocab_dir):\n",
    "    \"\"\"读取词汇表\"\"\"\n",
    "    with open(vocab_dir) as fp:\n",
    "        words = [(_.strip()) for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(path, csv_path):\n",
    "    '''\n",
    "    获得最终的数据集\n",
    "    path:文本数据集\n",
    "    csv_path\n",
    "    '''\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    target_csv = []\n",
    "    target_time_list = []\n",
    "    Max_len = -1\n",
    "    count = 0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\", sentence)\n",
    "            \n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path + '/'+foldtype + '/' + recipetype + '/' + video_name + '/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end) // 2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time / time_length * 500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            #上下文信息\n",
    "            target_frame_start = int(cur_start / time_length * 500)\n",
    "            target_frame_end = int(cur_end / time_length * 500)\n",
    "            if target_frame_start == target_frame_num:\n",
    "                target_frame_start = min(target_frame_num - 3, 0)\n",
    "            if  target_frame_end ==target_frame_num:\n",
    "                target_frame_start = min(target_frame_num + 3, 499)\n",
    "                \n",
    "            pre_context = np.zeros([target_frame_num - target_frame_start, 512], dtype=np.float32)\n",
    "            post_context = np.zeros([target_frame_end - target_frame_num, 512], dtype=np.float32) \n",
    "            for i in range(target_frame_num - target_frame_start):\n",
    "                pre_context[i] = frame_sum.loc[i]\n",
    "                \n",
    "            for i in range(target_frame_end - target_frame_num):\n",
    "                post_context[i] = frame_sum.loc[i]\n",
    "            \n",
    "            #对pre_context和post_context取均值\n",
    "            pre_context = np.mean(pre_context, axis=0)\n",
    "            post_context = np.mean(post_context, axis=0)\n",
    "            \n",
    "            #对三段信息进行拼接\n",
    "            image = np.hstack((pre_context, target_middle_frame, post_context))\n",
    "            \n",
    "            target_csv.append(image)\n",
    "            target_time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line + [0]*(Max_len - len(line)) \n",
    "                                               for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(target_csv),len(target_time_list))\n",
    "    \n",
    "    return batch_seq, target_csv, target_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_tarin_batch, target_train_csv, target_train_list = get_dict(train_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_val_batch, target_val_csv, target_val_list = get_dict(val_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(x_batch, target_csv, target_list, batch_size = 64):\n",
    "    \"\"\"\n",
    "    生成批次数据\n",
    "    \"\"\"\n",
    "    data_len = x_batch.shape[0]\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    \n",
    "    x_batch_shuffle = x_batch[indices]\n",
    "    y_csv_shuffle = np.array(target_csv)[indices]\n",
    "    target_list = np.array(target_list)[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_batch_shuffle[start_id:end_id], y_csv_shuffle[start_id:end_id], target_list[start_id:end_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TALL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TALL, self).__init__()\n",
    "        self.semantic_size = 128 # the size of visual and semantic comparison size\n",
    "        #self.sentence_embedding_size = 4800\n",
    "        self.visual_feature_dim = 1536\n",
    "        self.v2s_lt = nn.Linear(self.visual_feature_dim, self.semantic_size)#视觉提取\n",
    "        self.s2s_lt = nn.Linear(256, 128)#句子提取\n",
    "        self.fc1 = torch.nn.Conv2d(128*4, 128, kernel_size=1, stride=1)\n",
    "        self.fc2 = torch.nn.Conv2d(128, 3, kernel_size=1, stride=1)\n",
    "        # Initializing weights\n",
    "        self.apply(weights_init)\n",
    "        \n",
    "        #self_add\n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "\n",
    "    def cross_modal_comb(self, visual_feat, sentence_embed):\n",
    "        batch_size = visual_feat.size(0)\n",
    "        #print(\"进入交叉阶段,batch_size = \"+str(batch_size))\n",
    "\n",
    "        vv_feature = visual_feat.expand([batch_size, batch_size, self.semantic_size])\n",
    "        ss_feature = sentence_embed.repeat(1, 1, batch_size).view(batch_size, batch_size, self.semantic_size)\n",
    "\n",
    "        concat_feature = torch.cat([vv_feature, ss_feature], 2)\n",
    "\n",
    "        mul_feature = vv_feature * ss_feature # 64,64,128\n",
    "        add_feature = vv_feature + ss_feature # 64,64,128\n",
    "\n",
    "        comb_feature = torch.cat([mul_feature, add_feature, concat_feature], 2)\n",
    "\n",
    "        return comb_feature\n",
    "\n",
    "\n",
    "    def forward(self, visual_feature_train, sentence_embed_train):\n",
    "        transformed_clip_train = self.v2s_lt(visual_feature_train)\n",
    "        transformed_clip_train_norm = F.normalize(transformed_clip_train, p=2, dim=1)\n",
    "        \n",
    "        sentence_embed_train = self.embedding(sentence_embed_train)\n",
    "        sentence_embed_train,_ =self.lstm(sentence_embed_train)\n",
    "        transformed_sentence_train = self.s2s_lt(sentence_embed_train[:, -1, :])\n",
    "        transformed_sentence_train_norm = F.normalize(transformed_sentence_train, p=2, dim=1)\n",
    "        \n",
    "        cross_modal_vec_train = self.cross_modal_comb(transformed_clip_train_norm, transformed_sentence_train_norm)\n",
    "        \n",
    "        cross_modal_vec_train = cross_modal_vec_train.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        mid_output = self.fc1(cross_modal_vec_train)\n",
    "        mid_output = F.relu(mid_output)\n",
    "        sim_score_mat_train = self.fc2(mid_output).squeeze(0)\n",
    "        \n",
    "        return sim_score_mat_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_model = TALL()\n",
    "TALL_model.load_state_dict(torch.load(save_path + 'params.pkl'))\n",
    "lr = 0.01\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "optimizer = torch.optim.Adam(TALL_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(inital_epoch):\n",
    "    # compute alignment and regression loss\n",
    "    Max_loss = 1000\n",
    "    print(\"start traning.......\")\n",
    "    for epoch in range(EPOCH):\n",
    "        train_loss = 0\n",
    "        loss_align_sum = 0\n",
    "        loss_reg_sum = 0\n",
    "        count = 0\n",
    "        batch_train = batch_iter(sentence_tarin_batch, target_train_csv, target_train_list, BATCH_SIZE)\n",
    "        begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        for x_batch, y_csv, target_time in batch_train:\n",
    "            if y_csv.shape[0]==BATCH_SIZE:\n",
    "                count += 1\n",
    "                x = Variable(torch.LongTensor(x_batch))\n",
    "                y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                offsets = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                outputs = TALL_model(y, x)\n",
    "                sim_score_mat = outputs[0]\n",
    "                p_reg_mat = outputs[1]\n",
    "                l_reg_mat = outputs[2]\n",
    "                # loss cls, not considering iou\n",
    "                input_size = outputs.size(1)\n",
    "                I = torch.eye(input_size)\n",
    "                I_2 = -2 * I\n",
    "                all1 = torch.ones(input_size, input_size)\n",
    "\n",
    "                mask_mat = I_2 + all1  \n",
    "\n",
    "                alpha = 1.0 / input_size\n",
    "                lambda_regression = 0.01\n",
    "                batch_para_mat = alpha * all1\n",
    "                para_mat = I + batch_para_mat\n",
    "\n",
    "                loss_mat = torch.log(all1 + torch.exp(mask_mat*sim_score_mat))\n",
    "                loss_mat = loss_mat*para_mat\n",
    "                loss_align = loss_mat.mean()\n",
    "\n",
    "                # regression loss\n",
    "                l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "                p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "                offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "                loss_reg = torch.abs(offset_pred - offsets).mean() # L1 loss\n",
    "\n",
    "                loss= lambda_regression*loss_reg +loss_align\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss\n",
    "                loss_reg_sum += loss_reg\n",
    "                loss_align_sum += loss_align\n",
    "        \n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(begin_time+' | '+current_time+' | '+('Epoch: %d | Loss: %.3f | loss_align: %.3f | loss_reg: %.3f' % (inital_epoch + epoch, train_loss / (count), loss_align_sum / (count), loss_reg_sum / (count))))\n",
    "        train_loss_list.append(train_loss / (count))\n",
    "        \n",
    "        if (epoch + 1)%5 == 0:\n",
    "            print(\"validation.....\")\n",
    "            val_loss = 0\n",
    "            valloss_align_sum = 0\n",
    "            valloss_reg_sum = 0\n",
    "            count = 0\n",
    "            batch_val = batch_iter(sentence_val_batch, target_val_csv, target_val_list, BATCH_SIZE)\n",
    "            begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            for x_batch, y_csv, target_time in batch_val:\n",
    "                if y_csv.shape[0]==BATCH_SIZE:\n",
    "                    count += 1\n",
    "                    x = Variable(torch.LongTensor(x_batch))\n",
    "                    y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                    offsets = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                    outputs = TALL_model(y, x)\n",
    "                    sim_score_mat = outputs[0]\n",
    "                    p_reg_mat = outputs[1]\n",
    "                    l_reg_mat = outputs[2]\n",
    "                    input_size = outputs.size(1)\n",
    "                    I = torch.eye(input_size)\n",
    "                    I_2 = -2 * I\n",
    "                    all1 = torch.ones(input_size, input_size)\n",
    "\n",
    "                    mask_mat = I_2 + all1  \n",
    "\n",
    "                    alpha = 1.0 / input_size\n",
    "                    lambda_regression = 0.01\n",
    "                    batch_para_mat = alpha * all1\n",
    "                    para_mat = I + batch_para_mat\n",
    "\n",
    "                    loss_mat = torch.log(all1 + torch.exp(mask_mat*sim_score_mat))\n",
    "                    loss_mat = loss_mat*para_mat\n",
    "                    loss_align = loss_mat.mean()\n",
    "\n",
    "                    # regression loss\n",
    "                    l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "                    p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "                    offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "                    loss_reg = torch.abs(offset_pred - offsets).mean() # L1 loss\n",
    "\n",
    "                    loss= lambda_regression*loss_reg +loss_align\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    val_loss += loss\n",
    "                    valloss_reg_sum += loss_reg\n",
    "                    valloss_align_sum += loss_align\n",
    "            \n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            print(begin_time+' | '+current_time+' | '+('Epoch: %d | Loss: %.3f | loss_align: %.3f | loss_reg: %.3f' % (inital_epoch + epoch, val_loss / (count), valloss_align_sum / (count), valloss_reg_sum / (count))))\n",
    "            val_loss_list.append(val_loss / (count))\n",
    "            torch.save(TALL_model.state_dict(), save_path + 'epoch'+str(inital_epoch + epoch)+'params.pkl')\n",
    "            if val_loss / count < Max_loss:\n",
    "                Max_loss = val_loss / count\n",
    "                print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train(665)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(train_loss_list, val_loss_list):\n",
    "    x1 = range(0, len(train_loss_list))\n",
    "    x2 = range(0, len(val_loss_list))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, train_loss_list[:len(train_loss_list)], 'o-')\n",
    "    plt.title('train loss vs. epoches')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2,val_loss_list[:len(val_loss_list)] , '.-')\n",
    "    plt.xlabel('Val loss vs. epoches')\n",
    "    plt.ylabel('Val loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw(train_loss_list, val_loss_list)\n",
    "torch.save(TALL_model.state_dict(), save_path + 'final_model_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=256, num_layers=2, bidirectional=True)\n",
    "        self.f1 = nn.Sequential(nn.Linear(512,128), nn.Dropout(0.8), nn.ReLU())        \n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(512, 256, kernel_size=1, stride=1)\n",
    "        self.conv2 = torch.nn.Conv1d(256, 128, kernel_size=1, stride=1)\n",
    "\n",
    "        self.fc1=torch.nn.Linear(512,128)\n",
    "        self.fc1_drop=torch.nn.Dropout(p=0.4)\n",
    "        self.fc2=torch.nn.Linear(128, 64)\n",
    "        \n",
    "        #特征融合\n",
    "        self.final_fc = nn.Linear(in_features=256, out_features=128)\n",
    "        # Initializing weights\n",
    "        self.apply(weights_init)\n",
    "        \n",
    "        \n",
    "    def cnnout(self, x2):\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        out1 = self.conv1(x2)\n",
    "        out1_norm = F.normalize(out1, p=2, dim = 1)\n",
    "        out2 = self.conv2(out1_norm)\n",
    "        out2_norm = F.normalize(out2, p=2, dim = 1)\n",
    "        return out2_norm\n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        if x1.shape[0]!=2:\n",
    "            #lstm\n",
    "            x = self.embedding(x1)\n",
    "            x,_ = self.rnn(x)\n",
    "            x = F.dropout(x, p=0.8)\n",
    "            lstm_output = self.f1(x[:,-1,:])\n",
    "            #cnn\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            #concat\n",
    "            cnn_out = cnn_out.squeeze(2)\n",
    "            output = torch.cat((lstm_output, cnn_out), 1)\n",
    "            output = self.final_fc(output)\n",
    "            return output\n",
    "        else:\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            cnn_out = cnn_out.squeeze(2)\n",
    "            return cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class Change(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Change, self).__init__()\n",
    "        #特征融合\n",
    "        self.score_fc = torch.nn.Conv1d(128, 2, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = x#[10, 64]\n",
    "        output = output.unsqueeze(2)\n",
    "        score = self.score_fc(output)\n",
    "        offset_pred = score.squeeze(2)\n",
    "        return offset_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_final_model = TALL()\n",
    "My_model = Change()\n",
    "middle_model = LSTM_CNN()\n",
    "TALL_final_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/TALL/save_model/epoch754params.pkl'))\n",
    "middle_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/new_model_for_1500/543_params.pkl'))\n",
    "My_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/513.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 固定模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "My_model.eval()\n",
    "middle_model.eval()\n",
    "TALL_final_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IoU_thresh = [0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_IoU(i0, i1):\n",
    "    # calculate temporal intersection over union\n",
    "    union = (min(i0[0], i1[0]), max(i0[1], i1[1]))\n",
    "    inter = (max(i0[0], i1[0]), min(i0[1], i1[1]))\n",
    "    iou = 1.0*(inter[1]-inter[0])/(union[1]-union[0])\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_IoU_recall_top_n_forreg(iou_thresh, time_mat, time_pre_mat):#top\n",
    "    correct_num = 0\n",
    "    for i in range(time_mat.shape[0]):\n",
    "        gt_start = time_mat[i][0]\n",
    "        gt_end = time_mat[i][1]\n",
    "        pred_start = time_pre_mat[i][0]\n",
    "        pred_end = time_pre_mat[i][1]\n",
    "        iou = calculate_IoU((gt_start, gt_end),(pred_start, pred_end))\n",
    "        if iou>=iou_thresh:\n",
    "            correct_num+=1\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_for_TALL(outputs):\n",
    "    p_reg_mat = outputs[1]\n",
    "    l_reg_mat = outputs[2]\n",
    "    input_size = outputs.size(1)\n",
    "    I = torch.eye(input_size)\n",
    "    l_reg_diag = torch.mm(l_reg_mat*I, torch.ones(input_size, 1))\n",
    "    p_reg_diag = torch.mm(p_reg_mat*I, torch.ones(input_size, 1))\n",
    "    offset_pred = torch.cat([p_reg_diag, l_reg_diag], 1)\n",
    "    return offset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取test数据集\n",
    "def get_test_dict_for_TALL(path, csv_path):\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    csv=[]\n",
    "    time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[5].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end)//2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time/time_length*500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            #上下文信息\n",
    "            target_frame_start = int(cur_start/time_length*500)\n",
    "            target_frame_end = int(cur_end/time_length*500)\n",
    "            if target_frame_start == target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num - 3, 0)\n",
    "            if  target_frame_end ==target_frame_num:\n",
    "                print(str(cur_start)+\"  \"+str(cur_end)+\" \"+str(time_length))\n",
    "                print(\"出现重复！\")\n",
    "                target_frame_start = min(target_frame_num + 3, 499)\n",
    "                \n",
    "            pre_context = np.zeros([target_frame_num - target_frame_start, 512], dtype=np.float32)\n",
    "            post_context = np.zeros([target_frame_end - target_frame_num, 512], dtype=np.float32) \n",
    "            for i in range(target_frame_num - target_frame_start):\n",
    "                pre_context[i] = frame_sum.loc[i]\n",
    "                \n",
    "            for i in range(target_frame_end - target_frame_num):\n",
    "                post_context[i] = frame_sum.loc[i]\n",
    "            \n",
    "            #对pre_context和post_context取均值\n",
    "            pre_context = np.mean(pre_context, axis=0)\n",
    "            post_context = np.mean(post_context, axis=0)\n",
    "            \n",
    "            #对三段信息进行拼接\n",
    "            image = np.hstack((pre_context, target_middle_frame, post_context))\n",
    "            \n",
    "            csv.append(image)\n",
    "            time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(csv),len(time_list))\n",
    "    \n",
    "    return batch_seq, csv, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取test集\n",
    "# 读取test数据集\n",
    "def get_test_dict_for_My_model(path, csv_path):\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    csv=[]\n",
    "    time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[5].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path + '/' + foldtype + '/' + recipetype + '/' + video_name + '/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end) // 2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time / time_length * 500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            csv.append([target_middle_frame])\n",
    "            time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(csv),len(time_list))\n",
    "    \n",
    "    return batch_seq, csv, time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 读取test集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_test_seq, TALL_test_csv, TALL_test_time_list = get_test_dict_for_TALL(test_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "My_test_seq, My_test_csv, My_test_time_list = get_test_dict_for_My_model(test_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "my_model_time_list = []\n",
    "TALL_model_time_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TALL测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change(t):\n",
    "    return float(str(t)[6 : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    begin = datetime.datetime.now()\n",
    "    x = Variable(torch.LongTensor(TALL_test_seq))\n",
    "    y = Variable(torch.FloatTensor(np.array(TALL_test_csv)))\n",
    "    TALL_time_mat = Variable(torch.FloatTensor(np.array(TALL_test_time_list)))\n",
    "    TALL_outputs = TALL_final_model(y, x)\n",
    "    TALL_pre_time_mat = pred_for_TALL(TALL_outputs)\n",
    "    for iou_thresh in IoU_thresh:\n",
    "        corrnum = compute_IoU_recall_top_n_forreg(iou_thresh, TALL_time_mat, TALL_pre_time_mat)\n",
    "        corr_avg = corrnum * 1.0 / TALL_time_mat.shape[0] \n",
    "    end = datetime.datetime.now()\n",
    "    print(end - begin)\n",
    "    TALL_model_time_list.append(end - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My_model测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    begin = datetime.datetime.now()\n",
    "    x = Variable(torch.LongTensor(My_test_seq))\n",
    "    y = Variable(torch.FloatTensor(np.array(My_test_csv)))\n",
    "    My_time_mat = Variable(torch.FloatTensor(np.array(My_test_time_list)))\n",
    "    My_output1 = middle_model(x, y)\n",
    "    My_pred_time_mat = My_model(My_output1)\n",
    "    for iou_thresh in IoU_thresh:\n",
    "        corrnum = compute_IoU_recall_top_n_forreg(iou_thresh, My_time_mat, My_pred_time_mat)\n",
    "        corr_avg = corrnum * 1.0 / My_time_mat.shape[0] \n",
    "    end = datetime.datetime.now()\n",
    "    print(end - begin)\n",
    "    my_model_time_list.append(end - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比模型时间性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_model_time_list = [change(x) for x in TALL_model_time_list]\n",
    "my_model_time_list = [change(x) for x in my_model_time_list]\n",
    "x = np.linspace(1, 200, 200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(my_model_time_list[:50])\n",
    "print(TALL_model_time_list[:50])\n",
    "print(len(my_model_time_list))\n",
    "print(len(TALL_model_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_model_time_list = [x * 1000 for x in TALL_model_time_list]\n",
    "my_model_time_list = [x * 1000 for x in my_model_time_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_t(i):\n",
    "    if i==0:\n",
    "        return np.array(TALL_model_time_list)\n",
    "    else:\n",
    "        return np.array(my_model_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_name_list = ['TALL','My_model']\n",
    "color = ['blue','red']\n",
    "x = np.linspace(1, 200, 200)\n",
    "with plt.style.context(['science','ieee','no-latex']):\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(len(TALL_name_list)):\n",
    "        ax.plot(x, get_t(i),label=TALL_name_list[i],markersize=7,color=color[i])\n",
    "    ax.legend(title='run time',fontsize=6)\n",
    "    ax.set(xlabel='Rounds')\n",
    "    ax.set(ylabel='Time(ms)')\n",
    "    ax.set(ylabel='Time(ms)')\n",
    "    ax.autoscale(tight=True)\n",
    "    fig.savefig('time.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg(time_list):\n",
    "    sum=0.0\n",
    "    for i in range(len(time_list)):\n",
    "        sum+=time_list[i]\n",
    "    return sum/len(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TALL_avg=get_avg(TALL_model_time_list)\n",
    "my_avg=get_avg(my_model_time_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
