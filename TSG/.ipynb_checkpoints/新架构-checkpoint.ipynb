{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime  # 用于计算时间\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#import tensorflow.contrib.keras as kr\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from torchtext import data\n",
    "import jieba\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=15)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "\n",
    "import seaborn as sns\n",
    "# seaborn中文乱码解决方案\n",
    "from matplotlib.font_manager import FontProperties\n",
    "myfont=FontProperties(fname=r'C:\\Windows\\Fonts\\simhei.ttf',size=14)\n",
    "sns.set(font=myfont.get_name())\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_path = 'C:/Users/wuxun/Desktop/Data/feat_dat/'\n",
    "image_path = 'C:/Users/wuxun/Desktop/Data/image/'#存储到image文件夹中\n",
    "clip_path = 'C:/Users/wuxun/Desktop/Data/clip/'\n",
    "text_dir = 'C:/Users/wuxun/Desktop/Data/clear_text.txt'\n",
    "vocab_dir = 'C:/Users/wuxun/Desktop/Data/vocab.txt'\n",
    "train_path = 'C:/Users/wuxun/Desktop/Data/training/training.txt'\n",
    "val_path = 'C:/Users/wuxun/Desktop/Data/validation/validation.txt'\n",
    "csv_path = 'D:/csv/'\n",
    "save_path = 'C:/Users/wuxun/Desktop/Data/save_model/new_model_for_1500_for_logradioLoss_with_batch/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#固定随机数种子\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_resualt_file(path, line):\n",
    "    with open(path, 'a') as f:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(train_loss_list, val_loss_list):\n",
    "    x1 = range(0, len(train_loss_list))\n",
    "    x2 = range(0, len(val_loss_list))\n",
    "    #with plt.style.context(['science']):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x1, train_loss_list[:len(train_loss_list)], 'o-')\n",
    "    plt.title('train loss vs. epoches')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2,val_loss_list[:len(val_loss_list)] , '.-')\n",
    "    plt.xlabel('Val loss vs. epoches')\n",
    "    plt.ylabel('Val loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_data(data_list):\n",
    "    '''\n",
    "    绘制数据直方图分布\n",
    "    '''\n",
    "    print(type(data_list[0]))\n",
    "    print(len(data_list))\n",
    "    Max_v=-1;\n",
    "    Min_v=2000\n",
    "    for i in range(len(data_list)):\n",
    "        if data_list[i] > Max_v:\n",
    "            Max_v = data_list[i]\n",
    "        if data_list[i] < Min_v:\n",
    "            Min_v = data_list[i]\n",
    "    print(Max_v, Min_v)\n",
    "    num_block = int((Max_v - Min_v)/10)\n",
    "    print(num_block)\n",
    "    plt.hist(x = data_list, # 指定绘图数据\n",
    "         bins = num_block + 1, # 指定直方图中条块的个数\n",
    "         color = 'steelblue', # 指定直方图的填充色\n",
    "         edgecolor = 'black' # 指定直方图的边框色\n",
    "         )\n",
    "    # 添加x轴和y轴标签\n",
    "    plt.xlabel('偏差')\n",
    "    plt.ylabel('频数')\n",
    "    # 添加标题\n",
    "    plt.title('偏差分布')\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distance(x, y):\n",
    "    return np.sqrt(np.sum(np.square(x - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def close_grad(model):\n",
    "    '''\n",
    "    冻结模型\n",
    "    '''\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, inital_lr, lr_decay = 1e-2):\n",
    "    \"\"\"\n",
    "    Updates the learning rate given the learning rate decay.\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        if 'step' not in group:\n",
    "            group['step'] = 0\n",
    "        group['step'] += 1\n",
    "        group['lr'] = inital_lr / (1 + group['step'] * lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    for p in optimizer.param_groups:\n",
    "        lr = p['lr']\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def read_file(filename):\n",
    "\n",
    "    \"\"\"读取文件数据\"\"\"\n",
    "    \n",
    "    contents = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            contents.append(re.split('[, \\n.]',line))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(text_dir, vocab_dir, vocab_size=3000):\n",
    "\n",
    "    \"\"\"根据训练集构建词汇表，存储\"\"\"\n",
    "    data_train = read_file(text_dir)\n",
    "    all_data = []\n",
    "    for content in data_train:\n",
    "        for k in content:\n",
    "            if len(k)!=0:\n",
    "                all_data.append(k)\n",
    "    print(all_data)\n",
    "    counter = Counter(all_data)\n",
    "    count_pairs = counter.most_common(vocab_size - 1)\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    # 添加一个 <PAD> 来将所有文本pad为同一长度\n",
    "    words = ['<PAD>'] + list(words)\n",
    "    open(vocab_dir, mode='w').write('\\n'.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(vocab_dir):\n",
    "\n",
    "    \"\"\"读取词汇表\"\"\"\n",
    "\n",
    "    with open(vocab_dir) as fp:\n",
    "        words = [(_.strip()) for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_words(content, words):\n",
    "\n",
    "    \"\"\"将id表示的内容转换为文字\"\"\"\n",
    "\n",
    "    return ''.join(words[x] for x in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(path, csv_path):\n",
    "    '''\n",
    "    获得最终的数据集\n",
    "    path:文本数据集\n",
    "    csv_path\n",
    "    '''\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    source_csv=[]\n",
    "    target_csv=[]\n",
    "    source_time_list=[]\n",
    "    target_time_list=[]\n",
    "    distance_list = []\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            source = List[4]\n",
    "            target = List[5]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            #确定时间点\n",
    "            source = source.split('_')\n",
    "            target = target.split('_')\n",
    "            \n",
    "            source_time = (float(source[0]) + float(source[1])) // 2\n",
    "            source_time_len = np.abs(float(source[1]) - float(source[0]))\n",
    "            source_time_list.append([float(source[0]), float(source[1])])\n",
    "            source_frame_num = int(source_time / time_length * 500)\n",
    "            source_frame = frame_sum.loc[source_frame_num]\n",
    "            source_csv.append([source_frame])\n",
    "            \n",
    "            target_time = (float(target[0]) + float(target[1])) // 2\n",
    "            target_time_len = np.abs(float(target[1]) - float(target[0]))\n",
    "            target_time_list.append([float(target[0]), float(target[1])])\n",
    "            target_frame_num = int(target_time / time_length * 500)\n",
    "            target_frame = frame_sum.loc[target_frame_num]\n",
    "            target_csv.append([target_frame])\n",
    "            '''\n",
    "            gt_dist:中间值与长度的欧氏距离之和\n",
    "            '''\n",
    "            gt_dist = get_distance(source_time, target_time) + get_distance(source_time_len - target_time_len, 2)\n",
    "            distance_list.append([0, gt_dist])\n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0] * (Max_len - len(line)) for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)\n",
    "    print(len(batch_seq),len(source_csv),len(target_csv))\n",
    "    return batch_seq, source_csv, target_csv, source_time_list, target_time_list, distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(x_batch, x_csv, y_csv, source_list, target_list, distance_list, batch_size=64):\n",
    "    \"\"\"\n",
    "    生成批次数据\n",
    "    \"\"\"\n",
    "    data_len = x_batch.shape[0]\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_batch_shuffle = x_batch[indices]\n",
    "    x_csv_shuffle =np.array(x_csv)[indices]\n",
    "    y_csv_shuffle = np.array(y_csv)[indices]\n",
    "    source_list = np.array(source_list)[indices]\n",
    "    target_list = np.array(target_list)[indices]\n",
    "    distance_list = np.array(distance_list)[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_batch_shuffle[start_id:end_id], x_csv_shuffle[start_id:end_id], y_csv_shuffle[start_id:end_id], source_list[start_id:end_id], target_list[start_id:end_id], distance_list[start_id:end_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548 1548 1548\n",
      "523 523 523\n"
     ]
    }
   ],
   "source": [
    "#训练集\n",
    "x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, distance_train_list = get_dict(train_path, csv_path)\n",
    "#验证集\n",
    "x_batch_val, x_csv_val, y_csv_val, source_list_val, target_list_val, distance_val_list = get_dict(val_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "    参数初始化函数\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCN时间卷积网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        其实这就是一个裁剪的模块，裁剪多出来的padding\n",
    "        \"\"\"\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \"\"\"\n",
    "        相当于一个Residual block\n",
    "\n",
    "        :param n_inputs: int, 输入通道数\n",
    "        :param n_outputs: int, 输出通道数\n",
    "        :param kernel_size: int, 卷积核尺寸\n",
    "        :param stride: int, 步长，一般为1\n",
    "        :param dilation: int, 膨胀系数\n",
    "        :param padding: int, 填充系数\n",
    "        :param dropout: float, dropout比率\n",
    "        \"\"\"\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        # 经过conv1，输出的size其实是(Batch, input_channel, seq_len + padding)\n",
    "        self.chomp1 = Chomp1d(padding)  # 裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)  #  裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        参数初始化\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        TCN，目前paper给出的TCN结构很好的支持每个时刻为一个数的情况，即sequence结构，\n",
    "        对于每个时刻为一个向量这种一维结构，勉强可以把向量拆成若干该时刻的输入通道，\n",
    "        对于每个时刻为一个矩阵或更高维图像的情况，就不太好办。\n",
    "\n",
    "        :param num_inputs: int， 输入通道数\n",
    "        :param num_channels: list，每层的hidden_channel数，例如[25,25,25,25]表示有4个隐层，每层hidden_channel数为25\n",
    "        :param kernel_size: int, 卷积核尺寸\n",
    "        :param dropout: float, drop_out比率\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            '''\n",
    "            :512, [256, ]\n",
    "            '''\n",
    "            dilation_size = 2 ** i   # 膨胀系数：1，2，4，8……\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]  # 确定每一层的输入通道数\n",
    "            out_channels = num_channels[i]  # 确定每一层的输出通道数\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入x的结构不同于RNN，一般RNN的size为(Batch, seq_len, channels)或者(seq_len, Batch, channels)，\n",
    "        这里把seq_len放在channels后面，把所有时间步的数据拼起来，当做Conv1d的输入尺寸，实现卷积跨时间步的操作，\n",
    "        很巧妙的设计。\n",
    "        \n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return: size of (Batch, output_channel, seq_len)\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义LSTM的结构\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(5000, 64)\n",
    "        #self.rnn = nn.GRU(input_size=64, hidden_size=256, num_layers=2, bidirectional=True)\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=256, num_layers=2, bidirectional=True)\n",
    "        self.f1 = nn.Sequential(nn.Linear(512,128), nn.Dropout(0.8), nn.ReLU())        \n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(512, 256, kernel_size=1, stride=1)\n",
    "        self.conv2 = torch.nn.Conv1d(256, 128, kernel_size=1, stride=1)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(512,128)\n",
    "        self.fc1_drop = torch.nn.Dropout(p=0.4)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.final_fc = nn.Linear(in_features=256, out_features=128)\n",
    "        \n",
    "        # Initializing weights\n",
    "        self.apply(weights_init)\n",
    "        \n",
    "        \n",
    "    def cnnout(self, x2):\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        out1 = self.conv1(x2)\n",
    "        out1_norm = F.normalize(out1, p=2, dim = 1)\n",
    "        out2 = self.conv2(out1_norm)\n",
    "        out2_norm = F.normalize(out2, p=2, dim = 1)\n",
    "        return out2_norm\n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        if x1.shape[0]!=2:\n",
    "            '''\n",
    "            语义特征提取\n",
    "            '''\n",
    "            x = self.embedding(x1)\n",
    "            x,_ = self.rnn(x)\n",
    "            x = F.dropout(x, p=0.8)\n",
    "            lstm_output = self.f1(x[:,-1,:])\n",
    "            \n",
    "            '''\n",
    "            source帧特征提取\n",
    "            '''\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            \n",
    "            '''\n",
    "            文本与图像特征融合\n",
    "            '''\n",
    "            cnn_out = cnn_out.squeeze(2)\n",
    "            output = torch.cat((lstm_output, cnn_out), 1)\n",
    "            output = self.final_fc(output)\n",
    "            return output.unsqueeze(1)\n",
    "        \n",
    "        else:\n",
    "            '''\n",
    "            target帧特征提取\n",
    "            '''\n",
    "            cnn_out=self.cnnout(x2)\n",
    "            cnn_out = cnn_out.squeeze(2)\n",
    "            return cnn_out.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-RatioLoss 损失函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class L2dist(Function):\n",
    "#     '''\n",
    "#     L2 normal\n",
    "#     '''\n",
    "#     def __init__(self, p):\n",
    "#         super(L2dist, self).__init__()\n",
    "#         self.norm = p             # norm 2\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         eps = 1e-4 / x1.size(0)\n",
    "#         diff = torch.abs(x1 - x2)\n",
    "#         out = torch.pow(diff, self.norm).sum(dim = 1)\n",
    "#         return torch.pow(out + eps, 1. / self.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class LogRatioLoss(Function):\n",
    "#     \"\"\"Log ratio loss function. \"\"\"\n",
    "#     def __init__(self):\n",
    "#         super(LogRatioLoss, self).__init__()\n",
    "#         self.pdist = L2dist(2)    # norm 2\n",
    "\n",
    "#     def forward(self, input, gt_dist):#gt_dist:[2], input:[num, embed_size]\n",
    "#         m = input.size()[0] - 1   # #paired\n",
    "#         a = input[0]              # anchor\n",
    "#         p = input[1:]             # paired (postive, negtive)\n",
    "        \n",
    "#         # auxiliary variables\n",
    "#         idxs = torch.arange(1, m + 1)\n",
    "#         indc = idxs.repeat(m,1).t() < idxs.repeat(m,1)\n",
    "\n",
    "#         epsilon = 1e-6\n",
    "#         dist = self.pdist.forward(a, p)\n",
    "        \n",
    "#         log_dist = torch.log(dist + epsilon)\n",
    "#         log_gt_dist = torch.log(gt_dist + epsilon)\n",
    "        \n",
    "#         diff_log_dist = log_dist.repeat(m, 1).t() - log_dist.repeat(m, 1)#log相减就是相除\n",
    "#         diff_log_gt_dist = log_gt_dist.repeat(m, 1).t() - log_gt_dist.repeat(m, 1)\n",
    "\n",
    "#         #uniform weight coefficients \n",
    "#         wgt = indc.clone().float()\n",
    "#         wgt = wgt.div(wgt.sum())\n",
    "\n",
    "#         log_ratio_loss = (diff_log_dist - diff_log_gt_dist).pow(2)\n",
    "\n",
    "#         loss = log_ratio_loss\n",
    "#         loss = loss.mul(wgt).sum()\n",
    "\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改写的Log-radio-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L2dist_for_batch(Function):\n",
    "    '''\n",
    "    L2 normal\n",
    "    #a:[batch_size, embed_size]\n",
    "    #p:[batch_size, m, embed_size]\n",
    "    '''\n",
    "    def __init__(self, p):\n",
    "        super(L2dist_for_batch, self).__init__()\n",
    "        self.norm = p             # norm 2\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        eps = 1e-4 / x1.size(1)\n",
    "        x1 = x1.unsqueeze(1) \n",
    "        diff = torch.abs(x1 - x2)\n",
    "        out = torch.pow(diff, self.norm).sum(dim = 2)\n",
    "        return torch.pow(out + eps, 1. / self.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def op(dist, batch):\n",
    "    '''\n",
    "    [batch_size, m]\n",
    "    batch = dist.shape[0]\n",
    "    '''\n",
    "    dist_t = (dist[:, 0] - dist[:, 1]).reshape(batch, 1).expand(batch, 4).reshape(batch, 2, 2)\n",
    "    \n",
    "    o = torch.ones(2, 2)\n",
    "    b = torch.eye(2, 2)\n",
    "    t = torch.Tensor([[0, 1], [-1, 0]])\n",
    "    m = (torch.mul(o - b, t)).repeat(batch, 1).reshape(batch, 2, 2)\n",
    "\n",
    "    resualt = torch.mul(m, dist_t)\n",
    "    \n",
    "    return resualt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRatioLoss_for_batch(Function):\n",
    "    \"\"\"Log ratio loss function. \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LogRatioLoss_for_batch, self).__init__()\n",
    "        self.pdist = L2dist_for_batch(2)    # norm 2\n",
    "\n",
    "    def forward(self, input, gt_dist):#gt_dist:[batch_size, 2], input:[batch_size, num, embed_size]\n",
    "        m = input.size()[1] - 1   # #paired\n",
    "        a = input[:, 0, :]              # anchor\n",
    "        p = input[:, 1:m + 1, :]             # paired (postive, negtive)\n",
    "        \n",
    "        #a:[batch_size, embed_size]\n",
    "        #p:[batch_size, m, embed_size]\n",
    "        batch = input.size()[0]\n",
    "        idxs = torch.arange(1, m + 1)\n",
    "        indc = idxs.repeat(m,1).t() < idxs.repeat(m,1)\n",
    "\n",
    "        epsilon = 1e-6\n",
    "        dist = self.pdist.forward(a, p)\n",
    "        log_dist = torch.log(dist + epsilon)\n",
    "        log_gt_dist = torch.log(gt_dist + epsilon)\n",
    "        \n",
    "        '''\n",
    "        dist:torch.Size([2])  ->  [batch_size, 2]\n",
    "        log_dist:torch.Size([2]) ->  [batch_size, 2]\n",
    "        log_gt_dist:torch.Size([2]) ->  [batch_size, 2]\n",
    "        '''\n",
    "        diff_log_dist = op(log_dist, batch)\n",
    "        diff_log_gt_dist = op(log_gt_dist, batch)\n",
    "        '''\n",
    "        torch.Size([2, 2])->[batch_size,2,2]\n",
    "        torch.Size([2, 2])->[batch_size,2,2]\n",
    "        '''\n",
    "        wgt = indc.clone().float()\n",
    "        wgt = wgt.div(wgt.sum())\n",
    "        wgt = wgt.repeat(batch, 1).reshape(batch,2,2)\n",
    "        '''\n",
    "        [2,2]\n",
    "        '''\n",
    "        log_ratio_loss = (diff_log_dist - diff_log_gt_dist).pow(2)\n",
    "        '''\n",
    "        torch.Size([2, 2])\n",
    "        '''\n",
    "        loss = log_ratio_loss\n",
    "        loss = loss.mul(wgt).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(238.896438598632812)\n",
      "tensor(238.896423339843750)\n"
     ]
    }
   ],
   "source": [
    "# batch = 128\n",
    "# D = torch.ones(batch,2)\n",
    "# T = torch.ones(batch,3,512)\n",
    "# r = torch.ones(batch)\n",
    "# for i in range(batch):\n",
    "#     d = torch.rand(2)    \n",
    "#     t = torch.rand(3, 512)\n",
    "#     D[i]=d\n",
    "#     T[i]=t\n",
    "#     r[i]=LogRatioLoss().forward(t,d)\n",
    "# R = LogRatioLoss_for_batch().forward(T,D)\n",
    "# print(r.sum())\n",
    "# print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储loss数据\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(save_path, EPOCH = 200, inital_epoch = 0, batch_size = 64, inital_lr = 0.01, inital_model = None):\n",
    "    model = LSTM_CNN()\n",
    "    #加载模型\n",
    "    if inital_model is not None:\n",
    "        model.load_state_dict(torch.load(inital_model))\n",
    "    optimizer = optim.Adam(model.parameters(), lr = inital_lr)\n",
    "    T = Variable(torch.FloatTensor([[1.0,1.0],[1.0,1.0]]))\n",
    "    best_val_loss = 1000000\n",
    "    writer = SummaryWriter('runs/exp_for_log-radio-loss')\n",
    "    print(\"train begin......\")\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, distance_train_list, batch_size)\n",
    "        train_loss_sum = 0\n",
    "        train_loss_avg = 0\n",
    "        count = 0\n",
    "        begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_train:\n",
    "            if x_csv.shape[0] == batch_size:\n",
    "                count += 1\n",
    "                x1 = Variable(torch.LongTensor(x_batch))\n",
    "                x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                gt = Variable(torch.FloatTensor(distance)).squeeze(0)\n",
    "                pred_y = model(x1, x2)\n",
    "                negtive = model(T, x2)\n",
    "                postive = model(T, y)\n",
    "                '''\n",
    "                pair与anchor进行拼接\n",
    "                '''\n",
    "                print(pred_y.shape)\n",
    "                print(postive.shape)\n",
    "                print(negtive.shape)\n",
    "                embed = torch.cat((pred_y, postive, negtive), 1)\n",
    "                print(embed.shape)\n",
    "                print(gt.shape)\n",
    "                Loss = LogRatioLoss_for_batch().forward(embed, gt)\n",
    "\n",
    "                train_loss_sum += Loss\n",
    "                optimizer.zero_grad()\n",
    "                Loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        train_loss_avg = train_loss_sum / count\n",
    "        train_loss_list.append(train_loss_sum)\n",
    "        line = begin_time + ' | ' + current_time + (' | Epoch: %3d | Loss: %.6f | lr: %.6f' % (inital_epoch + epoch, train_loss_avg, get_learning_rate(optimizer)))\n",
    "        print(line)\n",
    "        write_resualt_file(save_path + 'resualt.txt', line)\n",
    "        adjust_learning_rate(optimizer = optimizer, inital_lr= inital_lr)\n",
    "        writer.add_scalar('train_loss', train_loss_sum, global_step = epoch)\n",
    "        writer.add_scalar('lr', get_learning_rate(optimizer), global_step = epoch)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\"进行验证.....\")\n",
    "            begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            val_loss_avg = 0\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, distance_val_list, batch_size)\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_val:\n",
    "                if x_csv.shape[0]==batch_size:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "                    gt = Variable(torch.FloatTensor(distance)).squeeze(0)\n",
    "                    pred_y = model(x1, x2)\n",
    "                    negtive = model(T, x2)\n",
    "                    postive = model(T, y)\n",
    "                    \n",
    "                    embed = torch.cat((pred_y, postive, negtive), 1)\n",
    "                    Loss = LogRatioLoss_for_batch().forward(embed, gt)\n",
    "                    \n",
    "                    val_loss_sum += Loss\n",
    "                    optimizer.zero_grad()\n",
    "                    Loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            val_loss_avg = val_loss_sum / count\n",
    "            val_loss_list.append(val_loss_sum) \n",
    "            line = begin_time + ' | ' + current_time + (' | Epoch: %3d | Loss: %.6f | lr: %.6f' % (inital_epoch + epoch, val_loss_avg, get_learning_rate(optimizer)))\n",
    "            print(line)\n",
    "            write_resualt_file(save_path + 'resualt.txt', line)  \n",
    "            writer.add_scalar('val_loss', val_loss_sum, global_step = epoch)\n",
    "            torch.save(model.state_dict(), save_path + str(inital_epoch + epoch)+'_params.pkl')\n",
    "            if val_loss_sum < best_val_loss:\n",
    "                best_val_loss = val_loss_sum\n",
    "                print(\"model save!\")\n",
    "    #关闭tensorboardX\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train begin......\n"
     ]
    }
   ],
   "source": [
    "train(save_path, EPOCH=300, inital_epoch=0, batch_size=64, inital_lr=0.01, inital_model=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 绘制Loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAESCAYAAADqoDJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDA4iIhKFwUFERKL8PwzlS4scBfE5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_list, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 定义LSTM的结构\n",
    "# class Change(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Change, self).__init__()\n",
    "#         self.score_fc = torch.nn.Conv2d(128, 3, kernel_size=1, stride=1)\n",
    "#         self.apply(weights_init)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         output = x    #[batch_size2, 128]\n",
    "#         output_expand = output.expand([batch_size2, batch_size2, 128])  #[batch_size2, batch_size2, 128]\n",
    "#         output_expand = output_expand.unsqueeze(0).permute(0, 3, 1, 2)  #[1,batch_size2,batch_size2,128]=>[1,128,batch_size2,batch_size2]\n",
    "#         score = self.score_fc(output_expand)\n",
    "#         score_out = F.normalize(score, p=2, dim = 1)\n",
    "#         score_out = score_out.squeeze(0) #[3, batch_size2, batch_size2]\n",
    "#         return score_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Change(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Change, self).__init__()\n",
    "        #特征融合\n",
    "        self.score_fc = torch.nn.Conv1d(128, 2, kernel_size=1, stride=1)\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x#[batch_size2, 128]\n",
    "        output = output.unsqueeze(2)\n",
    "        score = self.score_fc(output)\n",
    "        score_out = F.normalize(score, p=2, dim = 1)\n",
    "        offset_pred = score_out.squeeze(2)\n",
    "        return offset_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path2 = 'C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/'\n",
    "save_resualt_path2 = 'C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/resualt.txt'\n",
    "save_path2_with_align = 'C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2有alignment/'\n",
    "save_resualt_path2_with_align = 'C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2有alignment/resualt.txt'\n",
    "save_path2_GRU_with_align = 'C:/Users/wuxun/Desktop/Data/save_model2/model1_GRU_有alignment/'\n",
    "save_resualt_path2_GRU_with_align = 'C:/Users/wuxun/Desktop/Data/save_model2/model1_GRU_有alignment/resualt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_2_list=[]\n",
    "val_loss_2_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_for_Change_model_3(resualt_path, model_save_path, EPOCH=500, inital_epoch=0, lamba=0.01):\n",
    "    change_model = Change()\n",
    "    model = LSTM_CNN()\n",
    "    model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/new_model_for_1500/244_params.pkl'))\n",
    "    \n",
    "    #冻结基础模型参数\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #change_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/batchsize_is_1_19.pkl'))\n",
    "    optimizer = optim.Adam(change_model.parameters(), lr = 0.01)\n",
    "    best_val_loss_2 = 1000000\n",
    "    print(\"train begin......\")\n",
    "    for epoch in range(EPOCH):\n",
    "        batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, distance_train_list, batch_size2)\n",
    "        count = 0\n",
    "        train_loss_sum = 0\n",
    "        begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_train:\n",
    "            if x_csv.shape[0]==batch_size2:\n",
    "                count += 1\n",
    "                x1 = Variable(torch.LongTensor(x_batch))\n",
    "                x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                pred = model(x1, x2)\n",
    "                pred2 = change_model(pred)\n",
    "            \n",
    "                Loss = torch.abs(pred2 - target_time).mean()\n",
    "                \n",
    "                train_loss_sum += Loss\n",
    "                optimizer.zero_grad()\n",
    "                Loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())        \n",
    "        line = begin_time+' | '+current_time+(' | Epoch: %3d | Loss: %.6f |' % (inital_epoch + epoch, train_loss_sum / (count)))\n",
    "        print(line)\n",
    "        write_resualt_file(resualt_path, line)\n",
    "        train_loss_2_list.append(train_loss_sum / count)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\"进行验证.......\")\n",
    "            begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, distance_val_list, batch_size2)\n",
    "            count = 0\n",
    "            val_loss_sum = 0\n",
    "            for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_val:\n",
    "                if x_csv.shape[0]==batch_size2:\n",
    "                    count += 1\n",
    "                    x1 = Variable(torch.LongTensor(x_batch))\n",
    "                    x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "                    source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "                    target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "                    pred = model(x1, x2)\n",
    "                    pred2 = change_model(pred)\n",
    "                    \n",
    "                    Loss = torch.abs(pred2 - target_time).mean()\n",
    "\n",
    "                    val_loss_sum += Loss\n",
    "                    optimizer.zero_grad()\n",
    "                    Loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "            line = begin_time+' | '+current_time+(' | Epoch: %3d | Loss: %.6f |' % (inital_epoch + epoch, val_loss_sum / (count)))\n",
    "            print(line)\n",
    "            write_resualt_file(resualt_path, line)\n",
    "            val_loss_2_list.append(val_loss_sum / count) \n",
    "            torch.save(change_model.state_dict(), model_save_path + 'batchsize_is_64_the_first_model_300_' + str(inital_epoch + epoch)+'.pkl')\n",
    "            if (val_loss_sum / count ) < best_val_loss_2:\n",
    "                best_val_loss_2 = val_loss_sum / count\n",
    "                print(\"model save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train_2(resualt_path, model_save_path, EPOCH=500, inital_epoch=0, lamba=0.01, inital_model=None, inital_Change_model=None, inital_lr=0.01):\n",
    "#     change_model = Change()\n",
    "#     model = LSTM_CNN()\n",
    "#     epsilon = 1e-6\n",
    "#     if inital_model is not None:\n",
    "#         model.load_state_dict(torch.load(inital_model))\n",
    "#     #冻结基础模型参数\n",
    "#     model.eval()\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "#     if inital_Change_model is not None:\n",
    "#         change_model.load_state_dict(torch.load(inital_Change_model))\n",
    "        \n",
    "#     optimizer = optim.Adam(change_model.parameters(), lr = inital_lr)\n",
    "#     best_val_loss_2 = 1000000\n",
    "#     for epoch in range(EPOCH):\n",
    "#         batch_train = batch_iter(x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train, distance_train_list, batch_size2)\n",
    "#         count = 0\n",
    "#         train_loss_sum = 0\n",
    "#         train_alignmentloss_sum = 0\n",
    "#         train_regloss_sum =0\n",
    "#         begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "#         for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_train:\n",
    "#             if x_csv.shape[0]==batch_size2:\n",
    "#                 count += 1\n",
    "#                 x1 = Variable(torch.LongTensor(x_batch))\n",
    "#                 x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "#                 y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "#                 source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "#                 target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "#                 pred = model(x1, x2)\n",
    "#                 score = change_model(pred)\n",
    "#                 alignment_mat = score[0]\n",
    "#                 l_mat = score[1]\n",
    "#                 r_mat = score[2]\n",
    "\n",
    "#                 I = torch.eye(batch_size2)\n",
    "#                 allone = torch.ones(batch_size2, batch_size2)\n",
    "#                 mask = allone - 2 * I\n",
    "\n",
    "#                 l_reg = torch.mm(l_mat * I, torch.ones(batch_size2, 1))\n",
    "#                 r_reg = torch.mm(r_mat * I, torch.ones(batch_size2, 1))\n",
    "#                 offset_pred = torch.cat([l_reg, r_reg], 1)\n",
    "\n",
    "#                 loss_mat = torch.log(allone + torch.exp(mask * score[0] + epsilon))\n",
    "#                 para = I + 1.0 / batch_size2 * allone\n",
    "#                 loss_mat = loss_mat * para\n",
    "#                 loss_alignment = loss_mat.mean()\n",
    "#                 loss_reg = torch.abs(offset_pred - target_time).mean()\n",
    "                \n",
    "#                 #最终的损失函数\n",
    "#                 Loss = loss_reg * lamba + loss_alignment\n",
    "                \n",
    "#                 train_regloss_sum += loss_reg\n",
    "#                 train_loss_sum += Loss\n",
    "#                 train_alignmentloss_sum += loss_alignment\n",
    "#                 optimizer.zero_grad()\n",
    "#                 Loss.backward()\n",
    "#                 #nn.utils.clip_grad_norm_(change_model.parameters(), max_norm=20, norm_type=2)\n",
    "#                 optimizer.step()\n",
    "                \n",
    "#         current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())    \n",
    "#         line = begin_time+' | '+current_time+(' | Epoch: %3d | Loss: %.6f | loss_align: %.6f | loss_reg: %.6f' % (epoch, train_loss_sum / (count), train_alignmentloss_sum / (count), train_regloss_sum / (count)))\n",
    "#         print(line)\n",
    "#         write_resualt_file(resualt_path, line)\n",
    "#         train_loss_2_list.append(train_loss_sum / count)\n",
    "\n",
    "#         if (epoch + 1) % 5 == 0:\n",
    "#             print(\"进行验证.......\")\n",
    "#             begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "#             batch_val = batch_iter(x_batch_val, x_csv_val, y_csv_val,source_list_val,target_list_val, distance_val_list, batch_size2)\n",
    "#             count = 0\n",
    "#             val_loss_sum = 0\n",
    "#             val_alignmentloss_sum =0\n",
    "#             val_regloss_sum =0\n",
    "#             for x_batch, x_csv, y_csv, source_time, target_time, distance in batch_val:\n",
    "#                 if x_csv.shape[0]==batch_size2:\n",
    "#                     count += 1\n",
    "#                     x1 = Variable(torch.LongTensor(x_batch))\n",
    "#                     x2 = Variable(torch.FloatTensor(np.array(x_csv)))\n",
    "#                     y = Variable(torch.FloatTensor(np.array(y_csv)))\n",
    "#                     source_time = Variable(torch.FloatTensor(np.array(source_time)))\n",
    "#                     target_time = Variable(torch.FloatTensor(np.array(target_time)))\n",
    "#                     pred = model(x1, x2)\n",
    "#                     score = change_model(pred)\n",
    "                    \n",
    "#                     #特征变换\n",
    "#                     alignment_mat = score[0]\n",
    "#                     l_mat = score[1]\n",
    "#                     r_mat = score[2]\n",
    "\n",
    "#                     I = torch.eye(batch_size2)\n",
    "#                     allone = torch.ones(batch_size2, batch_size2)\n",
    "#                     mask = allone - 2 * I\n",
    "\n",
    "#                     l_reg = torch.mm(l_mat * I, torch.ones(batch_size2, 1))\n",
    "#                     r_reg = torch.mm(r_mat * I, torch.ones(batch_size2, 1))\n",
    "#                     offset_pred = torch.cat([l_reg, r_reg], 1)\n",
    "#                     loss_mat = torch.log(allone + torch.exp(mask * score[0] + epsilon))\n",
    "\n",
    "#                     para = I + 1.0 / batch_size2 * allone\n",
    "#                     loss_mat = loss_mat * para\n",
    "#                     loss_alignment = loss_mat.mean()\n",
    "#                     loss_reg = torch.abs(offset_pred - target_time).mean()\n",
    "                    \n",
    "#                     #模型最终的loss\n",
    "#                     Loss = loss_reg * lamba + loss_alignment\n",
    "                    \n",
    "#                     val_alignmentloss_sum += loss_alignment\n",
    "#                     val_regloss_sum += loss_reg\n",
    "#                     val_loss_sum += Loss\n",
    "#                     optimizer.zero_grad()\n",
    "                    \n",
    "#                     Loss.backward()\n",
    "#                     #nn.utils.clip_grad_norm_(change_model.parameters(), max_norm=20, norm_type=2)\n",
    "#                     optimizer.step()\n",
    "            \n",
    "#             current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "#             line = begin_time+' | '+current_time+(' | Epoch: %3d | Loss: %.6f | loss_align: %.6f | loss_reg: %.6f' % (epoch, val_loss_sum / (count), val_alignmentloss_sum / (count), val_regloss_sum / (count)))\n",
    "#             print(line)\n",
    "#             write_resualt_file(resualt_path, line)\n",
    "#             val_loss_2_list.append(val_loss_sum / count) \n",
    "#             torch.save(change_model.state_dict(), model_save_path + 'epoch_'+str(inital_epoch + epoch)+'.pkl')\n",
    "#             if (val_loss_sum / count ) < best_val_loss_2:\n",
    "#                 best_val_loss_2 = val_loss_sum / count\n",
    "#                 print(\"model save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_for_Change_model_3(save_resualt_path2_GRU_with_align, save_path2_GRU_with_align, EPOCH=500,  inital_epoch = 0, lamba = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inital_model = 'C:/Users/wuxun/Desktop/Data/save_model/new_model_for_1500/543_params.pkl'\n",
    "# train_2(save_resualt_path2_GRU_with_align, save_path2_GRU_with_align, 500, 0, 0.01, inital_model, None, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAESCAYAAADqoDJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDA4iIhKFwUFERKL8PwzlS4scBfE5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(train_loss_2_list, val_loss_2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算R@1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IoU_thresh = [0.1, 0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_IoU(i0, i1):\n",
    "    # calculate temporal intersection over union\n",
    "    union = (min(i0[0], i1[0]), max(i0[1], i1[1]))\n",
    "    inter = (max(i0[0], i1[0]), min(i0[1], i1[1]))\n",
    "    iou = 1.0*(inter[1]-inter[0])/(union[1]-union[0])\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_IoU_recall_top_n_forreg(iou_thresh, time_mat, time_pre_mat):#top\n",
    "    correct_num = 0\n",
    "    for i in range(time_mat.shape[0]):\n",
    "        gt_start = time_mat[i][0]\n",
    "        gt_end = time_mat[i][1]\n",
    "        pred_start = time_pre_mat[i][0]\n",
    "        pred_end = time_pre_mat[i][1]\n",
    "        iou = calculate_IoU((gt_start, gt_end),(pred_start, pred_end))\n",
    "        if iou>=iou_thresh:\n",
    "            correct_num+=1\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取test集\n",
    "# 读取test数据集\n",
    "def get_test_dict_for_My_model(path, csv_path):\n",
    "    words, word_to_id = read_vocab(vocab_dir)\n",
    "    data_id = []\n",
    "    csv=[]\n",
    "    time_list=[]\n",
    "    Max_len=-1\n",
    "    count=0\n",
    "    with open(path) as contents:\n",
    "        for line in contents:\n",
    "            count+=1\n",
    "            List = line.split('#')\n",
    "            video_name = List[0]\n",
    "            time_length = float(List[1])\n",
    "            foldtype = List[2]\n",
    "            recipetype = List[3]\n",
    "            target = List[4]\n",
    "            \n",
    "            #将句子转换为id表示：\n",
    "            sentence = List[6].strip('\\n').strip()\n",
    "            sentence = re.split(r\"[,| |.]\",sentence)\n",
    "            sentence_id = [word_to_id[x] for x in sentence if x in word_to_id]\n",
    "            if len(sentence_id) > Max_len:\n",
    "                Max_len = len(sentence_id)\n",
    "            data_id.append(sentence_id)\n",
    "            \n",
    "            #寻找路径,先统一取0001\n",
    "            dir_path = csv_path+'/'+foldtype+'/'+recipetype+'/'+video_name+'/0001/'\n",
    "            name = os.listdir(dir_path)[0]\n",
    "            dir_path = dir_path + name\n",
    "            \n",
    "            #读取csv文件\n",
    "            my_file = Path(dir_path)\n",
    "            if my_file.exists():\n",
    "                frame_sum = pd.read_csv(dir_path, header=None)\n",
    "            else:\n",
    "                print(\"目录不存在！\")\n",
    "            \n",
    "            #确定时间点，前帧后帧取pooling\n",
    "            target = target.split('_')\n",
    "            cur_start = float(target[0])\n",
    "            cur_end = float(target[1])\n",
    "            middle_time = (cur_start + cur_end)//2\n",
    "            \n",
    "            #中间帧\n",
    "            target_frame_num = int(middle_time/time_length*500)\n",
    "            target_middle_frame = frame_sum.loc[target_frame_num]\n",
    "            \n",
    "            csv.append([target_middle_frame])\n",
    "            time_list.append([cur_start, cur_end])\n",
    "            \n",
    "    #将所有的句子pad为同一最大长度\n",
    "    batch_data_id = np.array([line +[0]*(Max_len-len(line)) \n",
    "                                            for line in data_id])\n",
    "    batch_seq = torch.LongTensor(batch_data_id)    \n",
    "    print(len(batch_seq),len(csv),len(time_list))\n",
    "    \n",
    "    return batch_seq, csv, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523 523 523\n"
     ]
    }
   ],
   "source": [
    "My_test_seq, My_test_csv, My_test_time_list = get_test_dict_for_My_model(val_path, csv_path)\n",
    "#x_batch_train, x_csv_train, y_csv_train, source_list_train, target_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_CNN(\n",
       "  (embedding): Embedding(5000, 64)\n",
       "  (rnn): LSTM(64, 256, num_layers=2, bidirectional=True)\n",
       "  (f1): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): Dropout(p=0.8)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (conv2): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.4)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (final_fc): Linear(in_features=256, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_model = LSTM_CNN()\n",
    "middle_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model/new_model_for_1500/394_params.pkl'))\n",
    "My_model = Change()\n",
    "#My_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2无alignment/513.pkl'))\n",
    "My_model.load_state_dict(torch.load('C:/Users/wuxun/Desktop/Data/save_model2/新训练的model1以后训练model2有alignment/epoch_178.pkl'))\n",
    "My_model.eval()\n",
    "middle_model.eval()                                                                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-87e987a43dfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMy_test_csv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mMy_time_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMy_test_time_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mMy_output1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmiddle_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMy_output1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-89f150f776fc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m#lstm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mlstm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    129\u001b[0m             raise RuntimeError(\n\u001b[0;32m    130\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m--> 131\u001b[1;33m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "batch_size2 = 1\n",
    "for i in range(My_test_seq.shape[0]):\n",
    "    \n",
    "    x = Variable(torch.LongTensor(My_test_seq[i]))\n",
    "    y = Variable(torch.FloatTensor(np.array(My_test_csv[i])))\n",
    "    My_time_mat = Variable(torch.FloatTensor(np.array(My_test_time_list[i])))\n",
    "    My_output1 = middle_model(x, y)\n",
    "    score = My_model(My_output1)\n",
    "\n",
    "    #特征变换\n",
    "    alignment_mat = score[0]\n",
    "    l_mat = score[1]\n",
    "    r_mat = score[2]\n",
    "\n",
    "    I = torch.eye(batch_size2)\n",
    "    allone = torch.ones(batch_size2, batch_size2)\n",
    "    mask = allone - 2 * I\n",
    "\n",
    "    l_reg = torch.mm(l_mat * I, torch.ones(batch_size2, 1))\n",
    "    r_reg = torch.mm(r_mat * I, torch.ones(batch_size2, 1))\n",
    "    offset_pred = torch.cat([l_reg, r_reg], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_model: R@1 for iou_thresh: 0.1 is : 0.065\n",
      "My_model: R@1 for iou_thresh: 0.3 is : 0.025\n",
      "My_model: R@1 for iou_thresh: 0.5 is : 0.010\n",
      "My_model: R@1 for iou_thresh: 0.7 is : 0.002\n"
     ]
    }
   ],
   "source": [
    "My_pred_time_mat = offset_pred\n",
    "for iou_thresh in IoU_thresh:\n",
    "    corrnum = compute_IoU_recall_top_n_forreg(iou_thresh, My_time_mat, My_pred_time_mat)\n",
    "    corr_avg = corrnum*1.0 / My_time_mat.shape[0] \n",
    "    print(\"My_model: R@1 for iou_thresh: %.1f is : %.3f\" % (iou_thresh, corr_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算偏移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_middle_time_list(time_mat):\n",
    "    time_list = []\n",
    "    for i in range(time_mat.shape[0]):\n",
    "        begin = time_mat[i][0].detach().numpy()\n",
    "        end = time_mat[i][1].detach().numpy()\n",
    "        time_list.append((begin + end) / 2)\n",
    "    return time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_offset(My_time_mat, My_pred_time_mat):\n",
    "    '''\n",
    "    返回平均偏移值与offset_list\n",
    "    '''\n",
    "    pred_list_time = get_middle_time_list(My_pred_time_mat)\n",
    "    list_time = get_middle_time_list(My_time_mat)\n",
    "    avg = 0.0\n",
    "    offset_list = []\n",
    "    for i in range(len(list_time)):\n",
    "        offset = list_time[i] - pred_list_time[i]\n",
    "        offset_list.append(offset)\n",
    "        avg = avg + offset\n",
    "    avg = avg / len(list_time)\n",
    "    return avg, offset_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
